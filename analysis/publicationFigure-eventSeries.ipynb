{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.constants import epsilon_0, e as q_e\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "from matplotlib.colorbar import ColorbarBase\n",
    "from matplotlib.colors import LogNorm\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib as mpl\n",
    "# Enable LaTeX rendering\n",
    "mpl.rcParams['text.usetex'] = False\n",
    "# Set the global font size\n",
    "mpl.rcParams.update({'font.size': 12})\n",
    "\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import trimesh\n",
    "from trimesh.points import PointCloud\n",
    "\n",
    "from common_functions import *\n",
    "import time\n",
    "\n",
    "from scipy.spatial import cKDTree\n",
    "import pyvista as pv\n",
    "pv.set_jupyter_backend('trame')  # or 'panel' if using panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import geometry\n",
    "stacked_spheres = trimesh.load_mesh('../sphere-charging/geometry/stacked_spheres_frompython_cropped.stl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration_SW, iteration_PE = 17, 39\n",
    "\n",
    "# Simulation Parameters (used for time conversion)\n",
    "WORLD_XY_AREA_SQ_M = 400 * 300 / (1e6**2)  # World area (m^2)\n",
    "PE_Ele_FLUX = 4e-6 * 6.241509e18\n",
    "SW_ION_FLUX = 3e-7 * 6.241509e18\n",
    "SW_Ele_FLUX = 1.5e-6 * 6.241509e18 # still dont know why the SW ele flux gives a difference conversion factor\n",
    "\n",
    "# PE Conversion Factor\n",
    "PARTICLES_PER_ITERATION_PE = 81775\n",
    "CONVERT_ITERATION_PE_TIME = PARTICLES_PER_ITERATION_PE / WORLD_XY_AREA_SQ_M / PE_Ele_FLUX\n",
    "\n",
    "# SW Conversion Factor\n",
    "PARTICLES_PER_ITERATION_SW = 14208\n",
    "CONVERT_ITERATION_SW_TIME = PARTICLES_PER_ITERATION_SW / WORLD_XY_AREA_SQ_M / SW_ION_FLUX\n",
    "\n",
    "# SW Conversion Factor\n",
    "PARTICLES_PER_ITERATION_All = 4452\n",
    "CONVERT_ITERATION_All_TIME = PARTICLES_PER_ITERATION_All / WORLD_XY_AREA_SQ_M / SW_ION_FLUX\n",
    "\n",
    "print(f\"PE Factor {CONVERT_ITERATION_PE_TIME*1000} (ms/iteration), at {iteration_PE} time = {(iteration_PE-1)*CONVERT_ITERATION_PE_TIME}\")\n",
    "print(f\"SW Factor {CONVERT_ITERATION_SW_TIME*1000} (ms/iteration), at {iteration_SW} time = {(iteration_SW-1)*CONVERT_ITERATION_SW_TIME}\")\n",
    "#print(\"SW Time (s): \", (iteration_SW-1)*CONVERT_ITERATION_SW_TIME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "# Photons Case"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Import ROOT file and fieldmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration: choose one\n",
    "config = \"onlyphotoemission\"\n",
    "selectnum = 100000\n",
    "\n",
    "# Define directory and file list\n",
    "directory_path = \"/storage/scratch1/5/avira7/Grain-Charging-Simulation-Data/build-initial8max0.8final12-adjustedWorld-onlyPE/\"\n",
    "filelist = sorted(glob.glob(f\"{directory_path}/root/*iteration{iteration_PE}*{config}*_num{selectnum}.root\"))\n",
    "\n",
    "# Process each ROOT file\n",
    "for fileIN in filelist:\n",
    "    filename = os.path.basename(fileIN)\n",
    "    \n",
    "    print(filename)\n",
    "\n",
    "    # Extract iteration number\n",
    "    number_str = filename.split(\"_\")[1]\n",
    "    iterationNUM = int(''.join(filter(str.isdigit, number_str)))\n",
    "\n",
    "    # Extract config from filename (3rd part after split by \"_\")\n",
    "    config_from_file = filename.split(\"_\")[2]\n",
    "\n",
    "    # Read data\n",
    "    vars()[\"df_\"+config_from_file] = read_rootfile(filename, directory_path=directory_path+\"/root\")\n",
    "    print(\"df_\"+config_from_file)\n",
    "\n",
    "    print(\"-\" * 78)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if iteration_PE <10 :\n",
    "    filenames = sorted(glob.glob(f\"{directory_path}/fieldmaps/*00{iteration_PE}*{config}*.txt\"))\n",
    "else:\n",
    "    filenames = sorted(glob.glob(f\"{directory_path}/fieldmaps/*{iteration_PE}*{config}*.txt\")) \n",
    "print(filenames)\n",
    "\n",
    "# read in fieldmaps\n",
    "df_fieldmap  = read_data_format_efficient(filenames,scaling=True)\n",
    "fieldIN_PE = df_fieldmap[iteration_PE]\n",
    "\n",
    "del df_fieldmap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## create fieldmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SETTINGS HERE ARE OPTIMIZED FOR ITERATION 86 ##\n",
    "\n",
    "N_DOWNSAMPLE_EMAG = 1\n",
    "ARROW_VOXEL_SPACING = 0.02 \n",
    "Y_SLICE = 0.0 + stacked_spheres.centroid[1]  # This correctly uses the centroid's Y\n",
    "THICKNESS = 0.002\n",
    "VECTOR_SCALE_FACTOR = 4e-7\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# Voxel Downsampling Helper Function\n",
    "# ----------------------------------------------------\n",
    "def voxel_downsample_points(points, spacing):\n",
    "    \"\"\"\n",
    "    Selects one point per voxel defined by the spacing.\n",
    "    Assumes points are 3D, but only uses X and Z for 2D density control.\n",
    "    \"\"\"\n",
    "    min_x, _, min_z = points.min(axis=0)\n",
    "    \n",
    "    x_indices = np.floor((points[:, 0] - min_x) / spacing).astype(int)\n",
    "    z_indices = np.floor((points[:, 2] - min_z) / spacing).astype(int)\n",
    "    \n",
    "    max_x_index = x_indices.max() + 1\n",
    "    voxel_keys = z_indices * max_x_index + x_indices\n",
    "\n",
    "    _, unique_indices = np.unique(voxel_keys, return_index=True)\n",
    "    \n",
    "    return unique_indices\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# Step 0: Load, Filter, and Downsample Data\n",
    "# ----------------------------------------------------\n",
    "start_time = time.time()\n",
    "points = fieldIN_PE[\"pos\"]\n",
    "vectors = fieldIN_PE[\"E\"]\n",
    "magnitudes = fieldIN_PE[\"E_mag\"]\n",
    "\n",
    "initial_mask = (magnitudes > 0) #(points[:, 2] > 0) & \n",
    "points = points[initial_mask]\n",
    "vectors = vectors[initial_mask]\n",
    "magnitudes = magnitudes[initial_mask]\n",
    "\n",
    "points_ds = points[::N_DOWNSAMPLE_EMAG]\n",
    "vectors_ds = vectors[::N_DOWNSAMPLE_EMAG]\n",
    "magnitudes_ds = magnitudes[::N_DOWNSAMPLE_EMAG]\n",
    "\n",
    "point_cloud = pv.PolyData(points_ds)\n",
    "point_cloud[\"E_mag\"] = magnitudes_ds\n",
    "point_cloud[\"Ex_val\"] = vectors_ds[:,0]\n",
    "point_cloud[\"Ez_val\"] = vectors_ds[:,2]\n",
    "\n",
    "print(f\"Starting points (filtered by z > 0 & mag > 0): {len(points)}\")\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# Step 1: Geometry Setup and Slicing\n",
    "# ----------------------------------------------------\n",
    "start_time_geo = time.time()\n",
    "\n",
    "pv_spheres = pv.PolyData(\n",
    "    stacked_spheres.vertices,\n",
    "    np.hstack([np.full((len(stacked_spheres.faces), 1), 3), stacked_spheres.faces])\n",
    ").compute_normals()\n",
    "\n",
    "bbox_bounds = point_cloud.bounds\n",
    "bbox = pv.Box(bounds=bbox_bounds)\n",
    "pv_spheres_cropped = pv_spheres.clip_box(bbox, invert=False)\n",
    "\n",
    "normal = [0, 1, 0]\n",
    "\n",
    "# FIX: Use explicit center with Y_SLICE for the plane\n",
    "plane_center = [\n",
    "    (bbox_bounds[0] + bbox_bounds[1]) / 2,  # X center\n",
    "    Y_SLICE,                                  # Y at slice location\n",
    "    (bbox_bounds[4] + bbox_bounds[5]) / 2   # Z center\n",
    "]\n",
    "\n",
    "# Slice geometry at the same location\n",
    "geo_slice = pv_spheres_cropped.slice(normal=normal, origin=plane_center)  # <-- FIXED: Use plane_center\n",
    "print(f\"Geometry and slicing preparation complete in {time.time() - start_time_geo:.2f}s\")\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# Step 2: Vector Field Glyphs (Arrows)\n",
    "# ----------------------------------------------------\n",
    "start_time_vectors = time.time()\n",
    "\n",
    "vector_mask = np.abs(points_ds[:, 1] - Y_SLICE) < THICKNESS\n",
    "points_slice_full = points_ds[vector_mask]\n",
    "vectors_slice_full = vectors_ds[vector_mask]\n",
    "magnitudes_slice_full = magnitudes_ds[vector_mask]\n",
    "\n",
    "unique_indices = voxel_downsample_points(points_slice_full, ARROW_VOXEL_SPACING)\n",
    "\n",
    "points_slice = points_slice_full[unique_indices]\n",
    "vectors_slice = vectors_slice_full[unique_indices]\n",
    "magnitudes_slice = magnitudes_slice_full[unique_indices]\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# ADD ONE MORE COLUMN ON THE RIGHT EDGE\n",
    "# ----------------------------------------------------\n",
    "# Find the maximum X value in the current slice\n",
    "max_x = points_slice[:, 0].max()\n",
    "\n",
    "# Find all Z values that exist at or near the max X\n",
    "x_threshold = max_x - ARROW_VOXEL_SPACING / 2  # Points in the rightmost column\n",
    "rightmost_mask = points_slice[:, 0] >= x_threshold\n",
    "\n",
    "# Get unique Z values from the rightmost column\n",
    "z_values_right = points_slice[rightmost_mask, 2]\n",
    "\n",
    "# Create new points one spacing to the right\n",
    "new_x = max_x + ARROW_VOXEL_SPACING\n",
    "new_points = np.array([[new_x, Y_SLICE - 2*THICKNESS, z] for z in z_values_right])\n",
    "\n",
    "# Interpolate field values at these new points from the nearest neighbors\n",
    "# Use the existing points to find nearest field values\n",
    "from scipy.spatial import cKDTree\n",
    "tree = cKDTree(points_slice_full[:, [0, 2]])  # Only use X and Z for 2D lookup\n",
    "distances, indices = tree.query(new_points[:, [0, 2]], k=1)\n",
    "new_vectors = vectors_slice_full[indices]\n",
    "new_magnitudes = magnitudes_slice_full[indices]\n",
    "\n",
    "# Append the new column to existing data\n",
    "points_slice = np.vstack([points_slice, new_points])\n",
    "vectors_slice = np.vstack([vectors_slice, new_vectors])\n",
    "magnitudes_slice = np.concatenate([magnitudes_slice, new_magnitudes])\n",
    "# ----------------------------------------------------\n",
    "\n",
    "MAGNITUDE_MAX_CLAMP = ARROW_VOXEL_SPACING / VECTOR_SCALE_FACTOR / 2\n",
    "magnitudes_slice_clamped = np.clip(magnitudes_slice, a_min=None, a_max=MAGNITUDE_MAX_CLAMP)\n",
    "\n",
    "points_slice[:,1] = Y_SLICE - 2*THICKNESS\n",
    "vectors_slice[:,1] = 0.0 - 2*THICKNESS\n",
    "slice_mesh_vectors = pv.PolyData(points_slice)\n",
    "slice_mesh_vectors['vectors'] = vectors_slice\n",
    "slice_mesh_vectors['magnitude'] = magnitudes_slice_clamped\n",
    "\n",
    "print(f\"Points in vector slice (after density control + extra column): {len(points_slice)}, old length: {len(points_slice_full)}...\")\n",
    "\n",
    "arrow = pv.Arrow(tip_length=0.3, tip_radius=0.2, shaft_radius=0.04)\n",
    "glyphs = slice_mesh_vectors.glyph(\n",
    "    orient='vectors',\n",
    "    scale='magnitude',\n",
    "    factor=VECTOR_SCALE_FACTOR,\n",
    "    geom=arrow\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------\n",
    "# Step 3: Visualization\n",
    "# ----------------------------------------------------\n",
    "pl = pv.Plotter()\n",
    "pl.set_background('white')\n",
    "\n",
    "pl.add_mesh(geo_slice, color=\"black\", line_width=3, opacity=0.5)\n",
    "pl.add_mesh(glyphs, color='black', show_scalar_bar=False, line_width=4, opacity=1)\n",
    "\n",
    "pl.enable_parallel_projection()\n",
    "pl.enable_2d_style()\n",
    "pl.view_xz()\n",
    "\n",
    "#pl.screenshot(f'figures/fieldvectors_{config}#{iteration}.jpeg', scale=4)\n",
    "\n",
    "print(f\"Total execution time: {time.time() - start_time:.2f}s\")\n",
    "pl.show(jupyter_backend='static')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## create event series for single event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# First histogram: all photoelectrons\n",
    "incident_gamma = df_onlyphotoemission[(df_onlyphotoemission[\"Particle_Type\"] == \"gamma\")&(df_onlyphotoemission[\"Parent_ID\"] == 0.0)].drop_duplicates(subset=\"Event_Number\", keep=\"first\")\n",
    "photoelectron_creation = df_onlyphotoemission[df_onlyphotoemission[\"Particle_Type\"] == \"e-\"].drop_duplicates(subset=\"Event_Number\", keep=\"first\")\n",
    "bins = np.logspace(-4, 3.2, 200)\n",
    "\n",
    "# histogram counts\n",
    "hist_all, bin_edges = np.histogram(photoelectron_creation[\"Kinetic_Energy_Pre_MeV\"]*1e6, bins=bins, density=False)\n",
    "bin_widths = np.diff(bin_edges)\n",
    "bin_centers = 0.5*(bin_edges[1:] + bin_edges[:-1])\n",
    "\n",
    "# ----------------------------\n",
    "# Second histogram: only e- that actually leave\n",
    "last_e_event = df_onlyphotoemission[df_onlyphotoemission[\"Particle_Type\"] == \"e-\"].drop_duplicates(subset=\"Event_Number\", keep=\"last\")\n",
    "world_e_energy = last_e_event[(last_e_event[\"Volume_Name_Post\"]==\"physical_cyclic\") | \n",
    "                              (last_e_event[\"Volume_Name_Pre\"]==\"physical_cyclic\")]\n",
    "\n",
    "#matching_event_numbers = np.intersect1d(photoelectron_creation[\"Event_Number\"], world_e_energy[\"Event_Number\"])\n",
    "#initial_PEenergy_leading_toejection = photoelectron_creation[photoelectron_creation[\"Event_Number\"].isin(matching_event_numbers)]\n",
    "\n",
    "Zmin, Zmax = np.min(np.vstack(world_e_energy[\"Post_Step_Position_mm\"])[:,2]), np.max(np.vstack(world_e_energy[\"Post_Step_Position_mm\"])[:,2])\n",
    "ind = np.argwhere((np.vstack(world_e_energy[\"Post_Step_Position_mm\"])[:,2]>=Zmax*0.99) |\n",
    "                  (np.vstack(world_e_energy[\"Post_Step_Position_mm\"])[:,2]<=Zmin*0.99))\n",
    "# plt.plot(np.vstack(world_e_energy[\"Post_Step_Position_mm\"])[:,0], np.vstack(world_e_energy[\"Post_Step_Position_mm\"])[:,2], 'k.',markersize=0.1)\n",
    "# plt.plot(np.vstack(world_e_energy[\"Post_Step_Position_mm\"])[:,0][ind], np.vstack(world_e_energy[\"Post_Step_Position_mm\"])[:,2][ind], 'b.',markersize=0.1)\n",
    "# plt.show()\n",
    "\n",
    "# histogram counts\n",
    "counts_ejected, _ = np.histogram(np.vstack(world_e_energy[\"Kinetic_Energy_Post_MeV\"])[ind]*1e6, bins=bins, density=False)\n",
    "\n",
    "# ----------------------------\n",
    "# Scaling: scale the ejected counts to match total counts of all photoelectrons\n",
    "total_all = np.sum(hist_all)\n",
    "total_ejected = np.sum(counts_ejected)\n",
    "precent_ejected = total_ejected/total_all\n",
    "\n",
    "counts_ejected_scaled = counts_ejected\n",
    "\n",
    "# ----------------------------\n",
    "# Convert both to differential flux (counts per bin width)\n",
    "differential_allPE = hist_all / bin_widths\n",
    "differential_ejected_scaled = counts_ejected_scaled / bin_widths\n",
    "\n",
    "# Filter out zero/very small values to avoid isolated bars\n",
    "# Set a threshold based on the minimum reasonable value\n",
    "threshold = 0.1  # adjust as needed\n",
    "mask_all = differential_allPE > threshold\n",
    "mask_ejected = differential_ejected_scaled > threshold\n",
    "\n",
    "# Apply mask and replace filtered values with NaN for cleaner plotting\n",
    "diff_all_filtered = np.where(mask_all, differential_allPE, np.nan)\n",
    "diff_ejected_filtered = np.where(mask_ejected, differential_ejected_scaled, np.nan)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5,3.2))\n",
    "\n",
    "# Plot - using linewidth=0 removes the vertical lines between steps\n",
    "ax.step(bin_centers, diff_all_filtered, where='mid', color='darkblue', alpha=0.7, linewidth=1.5, label='All photoelectrons')\n",
    "ax.fill_between(bin_centers, diff_all_filtered, step='mid', color='darkblue', alpha=0.3, linewidth=0)\n",
    "\n",
    "ax.step(bin_centers, diff_ejected_filtered, where='mid', color='darkgreen', alpha=0.7, linewidth=1.5, label='Emitted e-')\n",
    "ax.fill_between(bin_centers, diff_ejected_filtered, step='mid', color='darkgreen', alpha=0.3, linewidth=0)\n",
    "\n",
    "# ----------------------------\n",
    "ax.set_xlabel(\"Photoelectron Energy (eV)\")\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_yscale(\"log\")\n",
    "ax.set_xlim([bins[0], 330])\n",
    "ax.set_ylabel(\"Differential Flux\")\n",
    "#ax.set_yticklabels([])\n",
    "ax.set_ylim(10)\n",
    "\n",
    "print(\"Average photoelectron energy: \", np.mean(photoelectron_creation[\"Kinetic_Energy_Pre_MeV\"]*1e6), \" eV\")\n",
    "print(\"# of photoelectrons: \", len(photoelectron_creation))\n",
    "print(f\"# of emitted e-, reaching the top surface: {len(ind)}\")\n",
    "print(f\"% emitted e-: {len(ind)/len(photoelectron_creation)*100:.5f}\")\n",
    "print(f\"% PE event: {len(photoelectron_creation)/len(incident_gamma)*100:.5f}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(photoelectron_creation[\"Event_Number\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_onlyphotoemission[df_onlyphotoemission[\"Event_Number\"]==3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_mask = np.abs(np.vstack(df_onlyphotoemission[\"Post_Step_Position_mm\"])[:,1] - Y_SLICE) < THICKNESS\n",
    "\n",
    "newdf = df_onlyphotoemission[slice_mask][#(df_onlyphotoemission[slice_mask][\"Volume_Name_Pre\"]==\"physical_cyclic\")&\\\n",
    "                                         (df_onlyphotoemission[slice_mask][\"Particle_Type\"]==\"e-\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_df = df_onlyphotoemission[#(df_onlyphotoemission[\"Volume_Name_Post\"] ==\"physical_cyclic\")&\\\n",
    "                 (df_onlyphotoemission[\"Particle_Type\"] ==\"gamma\")] #&\\\n",
    "                 #(df_onlyphotoemission[\"Process_Name_Pre\"] !=\"initStep\")]\n",
    "\n",
    "slice_mask = (np.vstack(select_df[\"Pre_Step_Position_mm\"])[:,0] <0)  & (np.abs(np.vstack(select_df[\"Post_Step_Position_mm\"])[:,1] - Y_SLICE) < THICKNESS)\n",
    "newdf = select_df[slice_mask] #& (np.vstack(select_df[\"Pre_Step_Position_mm\"])[:,0] > -0.10)\n",
    "\n",
    "newdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "test2= df_onlyphotoemission[df_onlyphotoemission[\"Event_Number\"]==61332][20:22] #[\"Kinetic_Energy_Pre_MeV\"]*1e6 #[\"Kinetic_Energy_Pre_MeV\"]*1e6 #[\"Kinetic_Energy_Diff_eV\"].sum() #67\n",
    "\n",
    "\n",
    "# # # # Compute per-row distances (vectorized)\n",
    "distances = np.linalg.norm(np.vstack(test2[\"Post_Step_Position_mm\"]) - np.vstack(test2[\"Pre_Step_Position_mm\"]), axis=1)\n",
    "np.sum(distances)*1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_onlyphotoemission[df_onlyphotoemission[\"Event_Number\"]==61332][19:22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "5.187194+34.939716"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section of geometry\n",
    "section = stacked_spheres.section(\n",
    "    plane_origin=stacked_spheres.centroid,\n",
    "    plane_normal=[0, 1, 0]\n",
    ")\n",
    "plane_point = stacked_spheres.centroid\n",
    "normal = np.array([0,1,0], float)\n",
    "\n",
    "# project vertices manually\n",
    "verts = section.vertices\n",
    "\n",
    "# project into plane (XY plane mapped as X,Z)\n",
    "V = verts       # center\n",
    "proj_x = V[:,0]              # global X\n",
    "proj_y = V[:,2]              # global Z\n",
    "\n",
    "# Setup plot\n",
    "fig, ax = plt.subplots(figsize=(8,7))\n",
    "\n",
    "for e in section.entities:\n",
    "    pts = e.points\n",
    "    ax.plot(proj_x[pts], proj_y[pts], 'k-',lw=2,alpha=0.5)\n",
    "\n",
    "for eventIN in [114, 99054, 61332]: #99633, , 67,2402, 99633, 649\n",
    "    # plot different particles as diffent colors\n",
    "    eventdf = df_onlyphotoemission[df_onlyphotoemission[\"Event_Number\"]==eventIN]\n",
    "    gamma_eventdf = eventdf[eventdf[\"Particle_Type\"] == \"gamma\"]\n",
    "    e_eventdf = eventdf[eventdf[\"Particle_Type\"] == \"e-\"]\n",
    "\n",
    "\n",
    "    # Correct physical interleaving\n",
    "    gamma_interwoven = np.empty((np.vstack(gamma_eventdf[\"Pre_Step_Position_mm\"]).shape[0] + np.vstack(gamma_eventdf[\"Post_Step_Position_mm\"]).shape[0], 3))\n",
    "    gamma_interwoven[0::2] = np.vstack(gamma_eventdf[\"Pre_Step_Position_mm\"])\n",
    "    gamma_interwoven[1::2] = np.vstack(gamma_eventdf[\"Post_Step_Position_mm\"])\n",
    "\n",
    "    # Correct physical interleaving\n",
    "    e_interwoven = np.empty((np.vstack(e_eventdf[\"Pre_Step_Position_mm\"]).shape[0] + np.vstack(e_eventdf[\"Post_Step_Position_mm\"]).shape[0], 3))\n",
    "    e_interwoven[0::2] = np.vstack(e_eventdf[\"Pre_Step_Position_mm\"])\n",
    "    e_interwoven[1::2] = np.vstack(e_eventdf[\"Post_Step_Position_mm\"])\n",
    "\n",
    "    # gamma_interwoven = np.unique(gamma_interwoven,axis=0)\n",
    "    # e_interwoven = np.unique(e_interwoven,axis=0)\n",
    "\n",
    "    ax.plot(gamma_interwoven[:, 0], gamma_interwoven[:,2], '-', markersize=6, color='blue', alpha=0.8,lw=4)\n",
    "    ax.plot(e_interwoven[:, 0], e_interwoven[:,2], '-', markersize=6, color='red',alpha=0.8,lw=2)\n",
    "ax.set_ylim([-0.2+0.030,0.203])\n",
    "ax.set_xlim([-0.2,0.2])\n",
    "ax.axis(\"off\")\n",
    "#plt.savefig(\"figures/PE_event_demo.svg\",transparent=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "## overlay with fieldmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import LineString, Polygon as ShapelyPolygon, MultiLineString\n",
    "from shapely.ops import unary_union, polygonize, linemerge\n",
    "from matplotlib.patches import Polygon\n",
    "import numpy as np\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,7))\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# Add PyVista geo_slice data to matplotlib\n",
    "# ----------------------------------------------------\n",
    "if geo_slice.n_cells > 0:\n",
    "    # Collect all line segments\n",
    "    lines = []\n",
    "    for i in range(geo_slice.n_cells):\n",
    "        cell = geo_slice.get_cell(i)\n",
    "        points = cell.points\n",
    "        \n",
    "        # Project to XZ plane (X, Z coordinates)\n",
    "        points_2d = points[:, [0, 2]]\n",
    "        \n",
    "        # Create line segments\n",
    "        if len(points_2d) >= 2:\n",
    "            lines.append(LineString(points_2d))\n",
    "    \n",
    "    if lines:\n",
    "        try:\n",
    "            # Create a MultiLineString\n",
    "            multi_line = MultiLineString(lines)\n",
    "            \n",
    "            # Merge connected line segments\n",
    "            merged = linemerge(multi_line)\n",
    "            \n",
    "            # Handle both single LineString and MultiLineString results\n",
    "            if isinstance(merged, LineString):\n",
    "                merged = [merged]\n",
    "            elif isinstance(merged, MultiLineString):\n",
    "                merged = list(merged.geoms)\n",
    "            \n",
    "            print(f\"Merged into {len(merged)} line groups\")\n",
    "            \n",
    "            # Try to close and fill each merged line group\n",
    "            for line in merged:\n",
    "                coords = np.array(line.coords)\n",
    "\n",
    "                patch = Polygon(coords, closed=True, facecolor='lightgray', \n",
    "                                edgecolor='none', alpha=0.4)\n",
    "                ax.add_patch(patch)\n",
    "                \n",
    "                # Draw the outline regardless\n",
    "                ax.plot(coords[:, 0], coords[:, 1], 'k-', linewidth=4, alpha=0.5)\n",
    "            \n",
    "            # Also try polygonize on the merged lines\n",
    "            polygons = list(polygonize(multi_line))\n",
    "            print(f\"Polygonize found {len(polygons)} polygons\")\n",
    "            \n",
    "            # for poly in polygons:\n",
    "            #     if poly.is_valid and poly.area > 1e-6:\n",
    "            #         coords = np.array(poly.exterior.coords)\n",
    "            #         patch = Polygon(coords, closed=True, facecolor='lightgray', \n",
    "            #                        edgecolor='none', alpha=0.4)\n",
    "            #         ax.add_patch(patch)\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            # Fallback: just draw the lines\n",
    "            for line in lines:\n",
    "                coords = np.array(line.coords)\n",
    "                ax.plot(coords[:, 0], coords[:, 1], 'k-', linewidth=4, alpha=0.5)\n",
    "\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# Add PyVista glyphs (field vectors) to matplotlib\n",
    "# ----------------------------------------------------\n",
    "# Extract arrow/vector data from glyphs\n",
    "if hasattr(glyphs, 'points') and glyphs.n_points > 0:\n",
    "    # Get start and end points of vectors\n",
    "    points = glyphs.points\n",
    "\n",
    "    # If glyphs are already arrow meshes, extract line segments\n",
    "    for i in range(glyphs.n_cells):\n",
    "        cell = glyphs.get_cell(i)\n",
    "        points_cell = cell.points\n",
    "        ax.plot(points_cell[:, 0], points_cell[:, 2], '-', linewidth=0.8, alpha=0.5, color=\"gray\")\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# Plot particle tracks\n",
    "# ----------------------------------------------------\n",
    "#for eventIN in [67,114]:\n",
    "for eventIN in [114, 99054, 61332]: #99633, , 67,2402, 99633\n",
    "    # plot different particles as different colors\n",
    "    eventdf = df_onlyphotoemission[df_onlyphotoemission[\"Event_Number\"]==eventIN]\n",
    "    gamma_eventdf = eventdf[eventdf[\"Particle_Type\"] == \"gamma\"]\n",
    "    e_eventdf = eventdf[eventdf[\"Particle_Type\"] == \"e-\"]\n",
    "\n",
    "    # Correct physical interleaving\n",
    "    gamma_interwoven = np.empty((np.vstack(gamma_eventdf[\"Pre_Step_Position_mm\"]).shape[0] + np.vstack(gamma_eventdf[\"Post_Step_Position_mm\"]).shape[0], 3))\n",
    "    gamma_interwoven[0::2] = np.vstack(gamma_eventdf[\"Pre_Step_Position_mm\"])\n",
    "    gamma_interwoven[1::2] = np.vstack(gamma_eventdf[\"Post_Step_Position_mm\"])\n",
    "\n",
    "    # Correct physical interleaving\n",
    "    e_interwoven = np.empty((np.vstack(e_eventdf[\"Pre_Step_Position_mm\"]).shape[0] + np.vstack(e_eventdf[\"Post_Step_Position_mm\"]).shape[0], 3))\n",
    "    e_interwoven[0::2] = np.vstack(e_eventdf[\"Pre_Step_Position_mm\"])\n",
    "    e_interwoven[1::2] = np.vstack(e_eventdf[\"Post_Step_Position_mm\"])\n",
    "\n",
    "    u, idx = np.unique(gamma_interwoven, axis=0, return_index=True)\n",
    "    gamma_interwoven = gamma_interwoven[np.sort(idx)]\n",
    "\n",
    "    u, idx = np.unique(e_interwoven, axis=0, return_index=True)\n",
    "    e_interwoven = e_interwoven[np.sort(idx)]\n",
    "\n",
    "    ax.plot(gamma_interwoven[:, 0], gamma_interwoven[:, 2], '-', markersize=10, color='green', alpha=0.9, lw=5)\n",
    "    ax.plot(e_interwoven[:, 0], e_interwoven[:, 2], '.-', markersize=10, color='blue', alpha=0.9, lw=3)\n",
    "\n",
    "ax.set_ylim([-0.2+0.030, 0.22])\n",
    "#ax.set_xlim([-0.2, 0.2])\n",
    "ax.set_aspect('equal')\n",
    "ax.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"figures/PE_event_demo_with_fields.svg\", transparent=True,dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "# Solar Wind Case"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "## Import ROOT file and fieldmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration: choose one\n",
    "config = \"onlysolarwind\"\n",
    "selectnum = 100000\n",
    "\n",
    "# Define directory and file list\n",
    "directory_path = \"/storage/scratch1/5/avira7/Grain-Charging-Simulation-Data/build-initial8max0.8final12-adjustedWorld-onlyPE/\"\n",
    "filelist = sorted(glob.glob(f\"{directory_path}/root/*iteration{iteration_SW}*{config}*_num{selectnum}.root\"))\n",
    "\n",
    "# Process each ROOT file\n",
    "for fileIN in filelist:\n",
    "    filename = os.path.basename(fileIN)\n",
    "    \n",
    "    print(filename)\n",
    "\n",
    "    # Extract iteration number\n",
    "    number_str = filename.split(\"_\")[1]\n",
    "    iterationNUM = int(''.join(filter(str.isdigit, number_str)))\n",
    "\n",
    "    # Extract config from filename (3rd part after split by \"_\")\n",
    "    config_from_file = filename.split(\"_\")[2]\n",
    "\n",
    "    # Read data\n",
    "    vars()[\"df_\"+config_from_file] = read_rootfile(filename, directory_path=directory_path+\"/root\")\n",
    "    print(\"df_\"+config_from_file)\n",
    "\n",
    "    print(\"-\" * 78)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "if iteration_SW <10 :\n",
    "    filenames = sorted(glob.glob(f\"{directory_path}/fieldmaps/*00{iteration_SW}*{config}*.txt\"))\n",
    "else:\n",
    "    filenames = sorted(glob.glob(f\"{directory_path}/fieldmaps/*{iteration_SW}*{config}*.txt\")) \n",
    "print(filenames)\n",
    "\n",
    "# read in fieldmaps\n",
    "df_fieldmap  = read_data_format_efficient(filenames,scaling=True)\n",
    "fieldIN_SW = df_fieldmap[iteration_SW]\n",
    "\n",
    "del df_fieldmap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "## create fieldmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SETTINGS HERE ARE OPTIMIZED FOR ITERATION 86 ##\n",
    "\n",
    "N_DOWNSAMPLE_EMAG = 1\n",
    "ARROW_VOXEL_SPACING = 0.02 \n",
    "Y_SLICE = 0.0 + stacked_spheres.centroid[1]  # This correctly uses the centroid's Y\n",
    "THICKNESS = 0.002\n",
    "VECTOR_SCALE_FACTOR = 7e-7 #8e-7 #3e-7\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# Voxel Downsampling Helper Function\n",
    "# ----------------------------------------------------\n",
    "def voxel_downsample_points(points, spacing):\n",
    "    \"\"\"\n",
    "    Selects one point per voxel defined by the spacing.\n",
    "    Assumes points are 3D, but only uses X and Z for 2D density control.\n",
    "    \"\"\"\n",
    "    min_x, _, min_z = points.min(axis=0)\n",
    "    \n",
    "    x_indices = np.floor((points[:, 0] - min_x) / spacing).astype(int)\n",
    "    z_indices = np.floor((points[:, 2] - min_z) / spacing).astype(int)\n",
    "    \n",
    "    max_x_index = x_indices.max() + 1\n",
    "    voxel_keys = z_indices * max_x_index + x_indices\n",
    "\n",
    "    _, unique_indices = np.unique(voxel_keys, return_index=True)\n",
    "    \n",
    "    return unique_indices\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# Step 0: Load, Filter, and Downsample Data\n",
    "# ----------------------------------------------------\n",
    "start_time = time.time()\n",
    "points = fieldIN_SW[\"pos\"]\n",
    "vectors = fieldIN_SW[\"E\"]\n",
    "magnitudes = fieldIN_SW[\"E_mag\"]\n",
    "\n",
    "initial_mask = (magnitudes > 0) #(points[:, 2] > 0) & \n",
    "points = points[initial_mask]\n",
    "vectors = vectors[initial_mask]\n",
    "magnitudes = magnitudes[initial_mask]\n",
    "\n",
    "points_ds = points[::N_DOWNSAMPLE_EMAG]\n",
    "vectors_ds = vectors[::N_DOWNSAMPLE_EMAG]\n",
    "magnitudes_ds = magnitudes[::N_DOWNSAMPLE_EMAG]\n",
    "\n",
    "point_cloud = pv.PolyData(points_ds)\n",
    "point_cloud[\"E_mag\"] = magnitudes_ds\n",
    "point_cloud[\"Ex_val\"] = vectors_ds[:,0]\n",
    "point_cloud[\"Ez_val\"] = vectors_ds[:,2]\n",
    "\n",
    "print(f\"Starting points (filtered by z > 0 & mag > 0): {len(points)}\")\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# Step 1: Geometry Setup and Slicing\n",
    "# ----------------------------------------------------\n",
    "start_time_geo = time.time()\n",
    "\n",
    "pv_spheres = pv.PolyData(\n",
    "    stacked_spheres.vertices,\n",
    "    np.hstack([np.full((len(stacked_spheres.faces), 1), 3), stacked_spheres.faces])\n",
    ").compute_normals()\n",
    "\n",
    "bbox_bounds = point_cloud.bounds\n",
    "bbox = pv.Box(bounds=bbox_bounds)\n",
    "pv_spheres_cropped = pv_spheres.clip_box(bbox, invert=False)\n",
    "\n",
    "normal = [0, 1, 0]\n",
    "\n",
    "# FIX: Use explicit center with Y_SLICE for the plane\n",
    "plane_center = [\n",
    "    (bbox_bounds[0] + bbox_bounds[1]) / 2,  # X center\n",
    "    Y_SLICE,                                  # Y at slice location\n",
    "    (bbox_bounds[4] + bbox_bounds[5]) / 2   # Z center\n",
    "]\n",
    "\n",
    "# Slice geometry at the same location\n",
    "geo_slice = pv_spheres_cropped.slice(normal=normal, origin=plane_center)  # <-- FIXED: Use plane_center\n",
    "print(f\"Geometry and slicing preparation complete in {time.time() - start_time_geo:.2f}s\")\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# Step 2: Vector Field Glyphs (Arrows)\n",
    "# ----------------------------------------------------\n",
    "start_time_vectors = time.time()\n",
    "\n",
    "vector_mask = np.abs(points_ds[:, 1] - Y_SLICE) < THICKNESS\n",
    "points_slice_full = points_ds[vector_mask]\n",
    "vectors_slice_full = vectors_ds[vector_mask]\n",
    "magnitudes_slice_full = magnitudes_ds[vector_mask]\n",
    "\n",
    "unique_indices = voxel_downsample_points(points_slice_full, ARROW_VOXEL_SPACING)\n",
    "\n",
    "points_slice = points_slice_full[unique_indices]\n",
    "vectors_slice = vectors_slice_full[unique_indices]\n",
    "magnitudes_slice = magnitudes_slice_full[unique_indices]\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# ADD ONE MORE COLUMN ON THE RIGHT EDGE\n",
    "# ----------------------------------------------------\n",
    "# Find the maximum X value in the current slice\n",
    "max_x = points_slice[:, 0].max()\n",
    "\n",
    "# Find all Z values that exist at or near the max X\n",
    "x_threshold = max_x - ARROW_VOXEL_SPACING / 2  # Points in the rightmost column\n",
    "rightmost_mask = points_slice[:, 0] >= x_threshold\n",
    "\n",
    "# Get unique Z values from the rightmost column\n",
    "z_values_right = points_slice[rightmost_mask, 2]\n",
    "\n",
    "# Create new points one spacing to the right\n",
    "new_x = max_x + ARROW_VOXEL_SPACING\n",
    "new_points = np.array([[new_x, Y_SLICE - 2*THICKNESS, z] for z in z_values_right])\n",
    "\n",
    "# Interpolate field values at these new points from the nearest neighbors\n",
    "# Use the existing points to find nearest field values\n",
    "from scipy.spatial import cKDTree\n",
    "tree = cKDTree(points_slice_full[:, [0, 2]])  # Only use X and Z for 2D lookup\n",
    "distances, indices = tree.query(new_points[:, [0, 2]], k=1)\n",
    "new_vectors = vectors_slice_full[indices]\n",
    "new_magnitudes = magnitudes_slice_full[indices]\n",
    "\n",
    "# Append the new column to existing data\n",
    "points_slice = np.vstack([points_slice, new_points])\n",
    "vectors_slice = np.vstack([vectors_slice, new_vectors])\n",
    "magnitudes_slice = np.concatenate([magnitudes_slice, new_magnitudes])\n",
    "# ----------------------------------------------------\n",
    "\n",
    "MAGNITUDE_MAX_CLAMP = ARROW_VOXEL_SPACING / VECTOR_SCALE_FACTOR / 2\n",
    "magnitudes_slice_clamped = np.clip(magnitudes_slice, a_min=None, a_max=MAGNITUDE_MAX_CLAMP)\n",
    "\n",
    "points_slice[:,1] = Y_SLICE - 2*THICKNESS\n",
    "vectors_slice[:,1] = 0.0 - 2*THICKNESS\n",
    "slice_mesh_vectors = pv.PolyData(points_slice)\n",
    "slice_mesh_vectors['vectors'] = vectors_slice\n",
    "slice_mesh_vectors['magnitude'] = magnitudes_slice_clamped\n",
    "\n",
    "print(f\"Points in vector slice (after density control + extra column): {len(points_slice)}, old length: {len(points_slice_full)}...\")\n",
    "\n",
    "arrow = pv.Arrow(tip_length=0.3, tip_radius=0.2, shaft_radius=0.04)\n",
    "glyphs = slice_mesh_vectors.glyph(\n",
    "    orient='vectors',\n",
    "    scale='magnitude',\n",
    "    factor=VECTOR_SCALE_FACTOR,\n",
    "    geom=arrow\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------\n",
    "# Step 3: Visualization\n",
    "# ----------------------------------------------------\n",
    "pl = pv.Plotter()\n",
    "pl.set_background('white')\n",
    "\n",
    "pl.add_mesh(geo_slice, color=\"black\", line_width=3, opacity=0.5)\n",
    "pl.add_mesh(glyphs, color='black', show_scalar_bar=False, line_width=4, opacity=1)\n",
    "\n",
    "pl.enable_parallel_projection()\n",
    "pl.enable_2d_style()\n",
    "pl.view_xz()\n",
    "\n",
    "#pl.screenshot(f'figures/fieldvectors_{config}#{iteration}.jpeg', scale=4)\n",
    "\n",
    "print(f\"Total execution time: {time.time() - start_time:.2f}s\")\n",
    "pl.show(jupyter_backend='static')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "## create event series for single event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_df = df_onlysolarwind[#(df_onlysolarwind[\"Volume_Name_Post\"] ==\"physical_cyclic\")&\\\n",
    "                 (df_onlysolarwind[\"Particle_Type\"] ==\"proton\")]#&\\\n",
    "                 #(df_onlysolarwind[\"Process_Name_Pre\"] !=\"initStep\")]\n",
    "\n",
    "slice_mask = (np.vstack(select_df[\"Pre_Step_Position_mm\"])[:,0] < 0) & (np.abs(np.vstack(select_df[\"Post_Step_Position_mm\"])[:,1] - Y_SLICE) < THICKNESS)\n",
    "newdf = select_df[slice_mask]\n",
    "\n",
    "np.unique(newdf[\"Event_Number\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "proton_events = df_onlysolarwind[df_onlysolarwind[\"Particle_Type\"]==\"proton\"]\n",
    "\n",
    "# Extract positions into arrays\n",
    "pre = np.vstack(proton_events[\"Pre_Step_Position_mm\"].to_numpy())\n",
    "post = np.vstack(proton_events[\"Post_Step_Position_mm\"].to_numpy())\n",
    "\n",
    "# Compute per-row distances (vectorized)\n",
    "distances = np.linalg.norm(post - pre, axis=1)\n",
    "\n",
    "# Add distances into dataframe\n",
    "proton_events = proton_events.assign(Distance_mm = distances)\n",
    "\n",
    "mask_SiO2 = (\n",
    "    (proton_events[\"Volume_Name_Pre\"] == \"SiO2\") &\n",
    "    (proton_events[\"Volume_Name_Post\"] == \"SiO2\")\n",
    ")\n",
    "\n",
    "# Keep only the SiO2-to-SiO2 steps\n",
    "subset = proton_events[mask_SiO2]\n",
    "\n",
    "# Sum distances per Event_Number\n",
    "distance_per_event_nm = (\n",
    "    subset.groupby(\"Event_Number\")[\"Distance_mm\"].sum() * 1e6  # mm → nm\n",
    ")\n",
    "\n",
    "plt.hist(distance_per_event_nm)\n",
    "plt.show()\n",
    "\n",
    "np.mean(distance_per_event_nm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "test2 = df_onlysolarwind[df_onlysolarwind[\"Event_Number\"]==37927][1:2] #[7:] #[\"Kinetic_Energy_Diff_eV\"].sum() #23236\n",
    "\n",
    "# # Compute per-row distances (vectorized)\n",
    "distances = np.linalg.norm(np.vstack(test2[\"Post_Step_Position_mm\"]) - np.vstack(test2[\"Pre_Step_Position_mm\"]), axis=1)\n",
    "np.sum(distances)*1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_onlysolarwind[df_onlysolarwind[\"Event_Number\"]==37927] #[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_per_event_nm[2253]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "85.172320+2.438480"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "electron_events = df_onlysolarwind[df_onlysolarwind[\"Particle_Type\"]==\"e-\"]\n",
    "\n",
    "# Extract positions into arrays\n",
    "pre = np.vstack(electron_events[\"Pre_Step_Position_mm\"].to_numpy())\n",
    "post = np.vstack(electron_events[\"Post_Step_Position_mm\"].to_numpy())\n",
    "\n",
    "# Compute per-row distances (vectorized)\n",
    "distances = np.linalg.norm(post - pre, axis=1)\n",
    "\n",
    "# Add distances into dataframe\n",
    "electron_events = electron_events.assign(Distance_mm = distances)\n",
    "\n",
    "mask_SiO2 = (\n",
    "    (electron_events[\"Volume_Name_Pre\"] == \"SiO2\") &\n",
    "    (electron_events[\"Volume_Name_Post\"] == \"SiO2\")\n",
    ")\n",
    "\n",
    "# Keep only the SiO2-to-SiO2 steps\n",
    "subset = electron_events[mask_SiO2]\n",
    "\n",
    "# Sum distances per Event_Number\n",
    "distance_per_event_nm = (\n",
    "    subset.groupby(\"Event_Number\")[\"Distance_mm\"].sum() * 1e6  # mm → nm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_per_event_nm[10297]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "70.554769+9.798563"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_df = df_onlysolarwind[(df_onlysolarwind[\"Volume_Name_Post\"] ==\"SiO2\")&\\\n",
    "                 (df_onlysolarwind[\"Particle_Type\"] ==\"e-\")&\\\n",
    "                 (df_onlysolarwind[\"Process_Name_Pre\"] !=\"initStep\")]\n",
    "\n",
    "slice_mask = (np.vstack(select_df[\"Pre_Step_Position_mm\"])[:,0] < -0.05) & (np.vstack(select_df[\"Pre_Step_Position_mm\"])[:,0] > -0.10) & (np.abs(np.vstack(select_df[\"Post_Step_Position_mm\"])[:,1] - Y_SLICE) < THICKNESS)\n",
    "newdf = select_df[slice_mask]\n",
    "\n",
    "newdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section of geometry\n",
    "section = stacked_spheres.section(\n",
    "    plane_origin=stacked_spheres.centroid,\n",
    "    plane_normal=[0, 1, 0]\n",
    ")\n",
    "normal = np.array([0,1,0], float)\n",
    "\n",
    "# project into plane (XY plane mapped as X,Z)\n",
    "verts = section.vertices\n",
    "V = verts     # center\n",
    "proj_x = V[:,0]              # global X\n",
    "proj_y = V[:,2]              # global Z\n",
    "\n",
    "# Setup plot\n",
    "fig, ax = plt.subplots(figsize=(8,7))\n",
    "\n",
    "for e in section.entities:\n",
    "    pts = e.points\n",
    "    ax.plot(proj_x[pts], proj_y[pts], 'k-',lw=2,alpha=0.5)\n",
    "\n",
    "for eventIN in [23236,2253,37927, ]: #62, 80, \n",
    "    # plot different particles as diffent colors\n",
    "    eventdf = df_onlysolarwind[df_onlysolarwind[\"Event_Number\"]==eventIN]\n",
    "    protons_eventdf = eventdf[eventdf[\"Particle_Type\"] == \"proton\"]\n",
    "\n",
    "    # Correct physical interleaving\n",
    "    proton_interwoven = np.empty((np.vstack(protons_eventdf[\"Pre_Step_Position_mm\"]).shape[0] + np.vstack(protons_eventdf[\"Post_Step_Position_mm\"]).shape[0], 3))\n",
    "    proton_interwoven[0::2] = np.vstack(protons_eventdf[\"Pre_Step_Position_mm\"])\n",
    "    proton_interwoven[1::2] = np.vstack(protons_eventdf[\"Post_Step_Position_mm\"])\n",
    "\n",
    "    #proton_interwoven = np.unique(proton_interwoven,axis=0)\n",
    "    #if eventIN == 80:\n",
    "    #ax.plot(proton_interwoven[1:, 0], proton_interwoven[1:,2], '.-', markersize=10, color='blue', alpha=0.8,lw=2)\n",
    "    #else:\n",
    "    ax.plot(proton_interwoven[:, 0], proton_interwoven[:,2], '.-', markersize=10, color='blue', alpha=0.8,lw=2)\n",
    "\n",
    "# for eventIN in [2865, 10297]: #17,99944]: \n",
    "#     # plot different particles as diffent colors\n",
    "#     eventdf = df_onlysolarwind[df_onlysolarwind[\"Event_Number\"]==eventIN]\n",
    "#     e_eventdf = eventdf[eventdf[\"Particle_Type\"] == \"e-\"]\n",
    "\n",
    "#     # Correct physical interleaving\n",
    "#     e_interwoven = np.empty((np.vstack(e_eventdf[\"Pre_Step_Position_mm\"]).shape[0] + np.vstack(e_eventdf[\"Post_Step_Position_mm\"]).shape[0], 3))\n",
    "#     e_interwoven[0::2] = np.vstack(e_eventdf[\"Pre_Step_Position_mm\"])\n",
    "#     e_interwoven[1::2] = np.vstack(e_eventdf[\"Post_Step_Position_mm\"])\n",
    "\n",
    "#     e_interwoven = np.unique(e_interwoven,axis=0)\n",
    "#     ax.plot(e_interwoven[:, 0], e_interwoven[:,2], '.-', markersize=10, color='red',alpha=0.8,lw=2)\n",
    "\n",
    "ax.set_ylim([-0.2+0.030,0.203])\n",
    "ax.set_xlim([-0.2,0.2])\n",
    "#ax.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section of geometry\n",
    "section = stacked_spheres.section(\n",
    "    plane_origin=stacked_spheres.centroid,\n",
    "    plane_normal=[0, 1, 0]\n",
    ")\n",
    "normal = np.array([0,1,0], float)\n",
    "\n",
    "# project into plane (XY plane mapped as X,Z)\n",
    "verts = section.vertices\n",
    "V = verts     # center\n",
    "proj_x = V[:,0]              # global X\n",
    "proj_y = V[:,2]              # global Z\n",
    "\n",
    "# Setup plot\n",
    "fig, ax = plt.subplots(figsize=(8,7))\n",
    "\n",
    "for e in section.entities:\n",
    "    pts = e.points\n",
    "    ax.plot(proj_x[pts], proj_y[pts], 'k-',lw=2,alpha=0.5)\n",
    "\n",
    "for eventIN in [2253,23236,98162]: #62, 80, \n",
    "    # plot different particles as diffent colors\n",
    "    eventdf = df_onlysolarwind[df_onlysolarwind[\"Event_Number\"]==eventIN]\n",
    "    protons_eventdf = eventdf[eventdf[\"Particle_Type\"] == \"proton\"]\n",
    "\n",
    "    # Correct physical interleaving\n",
    "    proton_interwoven = np.empty((np.vstack(protons_eventdf[\"Pre_Step_Position_mm\"]).shape[0] + np.vstack(protons_eventdf[\"Post_Step_Position_mm\"]).shape[0], 3))\n",
    "    proton_interwoven[0::2] = np.vstack(protons_eventdf[\"Pre_Step_Position_mm\"])\n",
    "    proton_interwoven[1::2] = np.vstack(protons_eventdf[\"Post_Step_Position_mm\"])\n",
    "\n",
    "    #proton_interwoven = np.unique(proton_interwoven,axis=0)\n",
    "    #if eventIN == 80:\n",
    "    #ax.plot(proton_interwoven[1:, 0], proton_interwoven[1:,2], '.-', markersize=10, color='blue', alpha=0.8,lw=2)\n",
    "    #else:\n",
    "    ax.plot(proton_interwoven[:, 0], proton_interwoven[:,2], '.-', markersize=10, color='blue', alpha=0.8,lw=2)\n",
    "\n",
    "# for eventIN in [2865]: #17,99944]: \n",
    "#     # plot different particles as diffent colors\n",
    "#     eventdf = df_onlysolarwind[df_onlysolarwind[\"Event_Number\"]==eventIN]\n",
    "#     e_eventdf = eventdf[eventdf[\"Particle_Type\"] == \"e-\"]\n",
    "\n",
    "#     # Correct physical interleaving\n",
    "#     e_interwoven = np.empty((np.vstack(e_eventdf[\"Pre_Step_Position_mm\"]).shape[0] + np.vstack(e_eventdf[\"Post_Step_Position_mm\"]).shape[0], 3))\n",
    "#     e_interwoven[0::2] = np.vstack(e_eventdf[\"Pre_Step_Position_mm\"])\n",
    "#     e_interwoven[1::2] = np.vstack(e_eventdf[\"Post_Step_Position_mm\"])\n",
    "\n",
    "#     e_interwoven = np.unique(e_interwoven,axis=0)\n",
    "#     ax.plot(e_interwoven[:, 0], e_interwoven[:,2], '.-', markersize=10, color='red',alpha=0.8,lw=2)\n",
    "\n",
    "ax.set_ylim([-0.2+0.030,0.203])\n",
    "ax.set_xlim([-0.2,0.2])\n",
    "#ax.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "eventIN = 37927\n",
    "eventdf = df_onlysolarwind[df_onlysolarwind[\"Event_Number\"]==eventIN]\n",
    "protons_eventdf = eventdf[eventdf[\"Particle_Type\"] == \"proton\"]\n",
    "\n",
    "# Setup plot\n",
    "fig, ax = plt.subplots(figsize=(8,7))\n",
    "\n",
    "for e in section.entities:\n",
    "    pts = e.points\n",
    "    ax.plot(proj_x[pts], proj_y[pts], 'k-',lw=2,alpha=0.5)\n",
    "\n",
    "# Correct physical interleaving\n",
    "proton_interwoven = np.empty((np.vstack(protons_eventdf[\"Pre_Step_Position_mm\"]).shape[0] + np.vstack(protons_eventdf[\"Post_Step_Position_mm\"]).shape[0], 3))\n",
    "proton_interwoven[0::2] = np.vstack(protons_eventdf[\"Pre_Step_Position_mm\"])\n",
    "proton_interwoven[1::2] = np.vstack(protons_eventdf[\"Post_Step_Position_mm\"])\n",
    "\n",
    "plt.plot(proton_interwoven[:, 0], proton_interwoven[:,2], '.-', markersize=10, color='r', alpha=0.8,lw=3)\n",
    "\n",
    "# plt.xlim(max(proton_interwoven[1:, 0]), min(proton_interwoven[:, 0]))\n",
    "# plt.ylim(max(proton_interwoven[1:, 2]), min(proton_interwoven[:, 2]))\n",
    "plt.xlim(-0.145491,-0.145489)\n",
    "plt.ylim(0.1677218,0.167723)\n",
    "ax.set_aspect('equal')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.diff([-0.145491,-0.145489])*1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ----------------------------------------------------\n",
    "# Step 2: Vector Field Glyphs (Arrows)\n",
    "# ----------------------------------------------------\n",
    "\n",
    "\n",
    "vector_mask = np.abs(points[:, 1] - Y_SLICE) < THICKNESS\n",
    "points_slice_full = points[vector_mask]\n",
    "vectors_slice_full = vectors[vector_mask]\n",
    "magnitudes_slice_full = magnitudes[vector_mask]\n",
    "\n",
    "\n",
    "# Get the range of proton_interwoven data\n",
    "x_min, x_max = proton_interwoven[1:, 0].min(), proton_interwoven[1:, 0].max()\n",
    "z_min, z_max = proton_interwoven[1:, 2].min(), proton_interwoven[1:, 2].max()\n",
    "\n",
    "# Filter points_slice to only include points within this range\n",
    "# Assuming points_slice has columns [x, y, z]\n",
    "range_mask = (\n",
    "    (points_slice_full[:, 0] >= x_min) & (points_slice_full[:, 0] <= x_max) &\n",
    "    (points_slice_full[:, 2] >= z_min) & (points_slice_full[:, 2] <= z_max)\n",
    ")\n",
    "\n",
    "points_slice_filtered = points_slice_full[range_mask]\n",
    "vectors_slice_filtered = vectors_slice_full[range_mask]\n",
    "magnitudes_slice_filtered = magnitudes_slice_full[range_mask]\n",
    "\n",
    "print(f\"Original points: {len(points_slice_full)}\")\n",
    "print(f\"Filtered points: {len(points_slice_filtered)}\")\n",
    "print(f\"X range: [{x_min:.6f}, {x_max:.6f}]\")\n",
    "print(f\"Z range: [{z_min:.6f}, {z_max:.6f}]\")\n",
    "\n",
    "unique_indices = voxel_downsample_points(points_slice_full, ARROW_VOXEL_SPACING)\n",
    "\n",
    "points_slice = points_slice_full[unique_indices]\n",
    "vectors_slice = vectors_slice_full[unique_indices]\n",
    "magnitudes_slice = magnitudes_slice_full[unique_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "points_slice_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "min(points_slice_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_min - x_max)*1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "xmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "points_slice_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.xlim(max(proton_interwoven[2:, 0]), min(proton_interwoven[2:, 0]))\n",
    "# plt.ylim(max(proton_interwoven[2:, 2]), min(proton_interwoven[2:, 2]))\n",
    "# plt.xlim(-0.04108,-0.04095)\n",
    "# plt.ylim(0.17505,0.17514)\n",
    "ax.set_aspect('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.diff(proton_interwoven[4:6, 0])*1000000\n",
    "\n",
    "0.5/0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "min(proton_interwoven[1:, 0])*0.999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "max(proton_interwoven[1:, 0])*1.0003"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56",
   "metadata": {},
   "source": [
    "## overlay with fieldmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import LineString, Polygon as ShapelyPolygon, MultiLineString\n",
    "from shapely.ops import unary_union, polygonize, linemerge\n",
    "from matplotlib.patches import Polygon\n",
    "import numpy as np\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,7))\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# Add PyVista geo_slice data to matplotlib\n",
    "# ----------------------------------------------------\n",
    "if geo_slice.n_cells > 0:\n",
    "    # Collect all line segments\n",
    "    lines = []\n",
    "    for i in range(geo_slice.n_cells):\n",
    "        cell = geo_slice.get_cell(i)\n",
    "        points = cell.points\n",
    "        \n",
    "        # Project to XZ plane (X, Z coordinates)\n",
    "        points_2d = points[:, [0, 2]]\n",
    "        \n",
    "        # Create line segments\n",
    "        if len(points_2d) >= 2:\n",
    "            lines.append(LineString(points_2d))\n",
    "    \n",
    "    if lines:\n",
    "        try:\n",
    "            # Create a MultiLineString\n",
    "            multi_line = MultiLineString(lines)\n",
    "            \n",
    "            # Merge connected line segments\n",
    "            merged = linemerge(multi_line)\n",
    "            \n",
    "            # Handle both single LineString and MultiLineString results\n",
    "            if isinstance(merged, LineString):\n",
    "                merged = [merged]\n",
    "            elif isinstance(merged, MultiLineString):\n",
    "                merged = list(merged.geoms)\n",
    "            \n",
    "            print(f\"Merged into {len(merged)} line groups\")\n",
    "            \n",
    "            # Try to close and fill each merged line group\n",
    "            for line in merged:\n",
    "                coords = np.array(line.coords)\n",
    "\n",
    "                patch = Polygon(coords, closed=True, facecolor='lightgray', \n",
    "                                edgecolor='none', alpha=0.4)\n",
    "                ax.add_patch(patch)\n",
    "                \n",
    "                # Draw the outline regardless\n",
    "                ax.plot(coords[:, 0], coords[:, 1], 'k-', linewidth=4, alpha=0.6)\n",
    "            \n",
    "            # Also try polygonize on the merged lines\n",
    "            polygons = list(polygonize(multi_line))\n",
    "            print(f\"Polygonize found {len(polygons)} polygons\")\n",
    "            \n",
    "            # for poly in polygons:\n",
    "            #     if poly.is_valid and poly.area > 1e-6:\n",
    "            #         coords = np.array(poly.exterior.coords)\n",
    "            #         patch = Polygon(coords, closed=True, facecolor='lightgray', \n",
    "            #                        edgecolor='none', alpha=0.4)\n",
    "            #         ax.add_patch(patch)\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            # Fallback: just draw the lines\n",
    "            for line in lines:\n",
    "                coords = np.array(line.coords)\n",
    "                ax.plot(coords[:, 0], coords[:, 1], 'k-', linewidth=4, alpha=0.5)\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# Add PyVista glyphs (field vectors) to matplotlib\n",
    "# ----------------------------------------------------\n",
    "# Extract arrow/vector data from glyphs\n",
    "if hasattr(glyphs, 'points') and glyphs.n_points > 0:\n",
    "    # Get start and end points of vectors\n",
    "    points = glyphs.points\n",
    "\n",
    "    # If glyphs are already arrow meshes, extract line segments\n",
    "    for i in range(glyphs.n_cells):\n",
    "        cell = glyphs.get_cell(i)\n",
    "        points_cell = cell.points\n",
    "        ax.plot(points_cell[:, 0], points_cell[:, 2], '-', linewidth=0.8, alpha=0.5, color=\"gray\")\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# Plot particle tracks\n",
    "# ----------------------------------------------------\n",
    "for eventIN in [2253,23236,37927]: #[62,80]: \n",
    "    # plot different particles as diffent colors\n",
    "    eventdf = df_onlysolarwind[df_onlysolarwind[\"Event_Number\"]==eventIN]\n",
    "    protons_eventdf = eventdf[eventdf[\"Particle_Type\"] == \"proton\"]\n",
    "\n",
    "    # Correct physical interleaving\n",
    "    proton_interwoven = np.empty((np.vstack(protons_eventdf[\"Pre_Step_Position_mm\"]).shape[0] + np.vstack(protons_eventdf[\"Post_Step_Position_mm\"]).shape[0], 3))\n",
    "    proton_interwoven[0::2] = np.vstack(protons_eventdf[\"Pre_Step_Position_mm\"])\n",
    "    proton_interwoven[1::2] = np.vstack(protons_eventdf[\"Post_Step_Position_mm\"])\n",
    "\n",
    "\n",
    "    if eventIN == 80:\n",
    "        ax.plot(proton_interwoven[:, 0], proton_interwoven[:,2], '.-', markersize=10, color='blue', alpha=0.8,lw=2)\n",
    "    else:\n",
    "\n",
    "        u, idx = np.unique(proton_interwoven, axis=0, return_index=True)\n",
    "        proton_interwoven = proton_interwoven[np.sort(idx)]\n",
    "        \n",
    "        ax.plot(proton_interwoven[:2, 0], proton_interwoven[:2,2], '-', color='red', alpha=0.8,lw=5)\n",
    "        ax.plot(proton_interwoven[:, 0], proton_interwoven[:,2], '.-', markersize=10, color='red', alpha=0.8,lw=3)\n",
    "\n",
    "# for eventIN in [2865]: #[99944,17]: \n",
    "#     # plot different particles as diffent colors\n",
    "#     eventdf = df_onlysolarwind[df_onlysolarwind[\"Event_Number\"]==eventIN]\n",
    "#     e_eventdf = eventdf[eventdf[\"Particle_Type\"] == \"e-\"]\n",
    "\n",
    "#     # Correct physical interleaving\n",
    "#     e_interwoven = np.empty((np.vstack(e_eventdf[\"Pre_Step_Position_mm\"]).shape[0] + np.vstack(e_eventdf[\"Post_Step_Position_mm\"]).shape[0], 3))\n",
    "#     e_interwoven[0::2] = np.vstack(e_eventdf[\"Pre_Step_Position_mm\"])\n",
    "#     e_interwoven[1::2] = np.vstack(e_eventdf[\"Post_Step_Position_mm\"])\n",
    "\n",
    "#     u, idx = np.unique(e_interwoven, axis=0, return_index=True)\n",
    "#     e_interwoven = e_interwoven[np.sort(idx)]\n",
    "\n",
    "#     ax.plot(e_interwoven[:2, 0], e_interwoven[:2,2], '-', color='blue', alpha=0.8,lw=5)\n",
    "#     ax.plot(e_interwoven[:, 0], e_interwoven[:,2], '-', markersize=10, color='blue',alpha=0.8,lw=5)\n",
    "\n",
    "ax.set_ylim([-0.2+0.030, 0.22])\n",
    "#ax.set_xlim([-0.2, 0.2])\n",
    "ax.set_aspect('equal')\n",
    "ax.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"figures/SW_event_demo_with_fields.svg\", transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import LineString, Polygon as ShapelyPolygon, MultiLineString\n",
    "from shapely.ops import unary_union, polygonize, linemerge\n",
    "from matplotlib.patches import Polygon\n",
    "import numpy as np\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,7))\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# Add PyVista geo_slice data to matplotlib\n",
    "# ----------------------------------------------------\n",
    "if geo_slice.n_cells > 0:\n",
    "    # Collect all line segments\n",
    "    lines = []\n",
    "    for i in range(geo_slice.n_cells):\n",
    "        cell = geo_slice.get_cell(i)\n",
    "        points = cell.points\n",
    "        \n",
    "        # Project to XZ plane (X, Z coordinates)\n",
    "        points_2d = points[:, [0, 2]]\n",
    "        \n",
    "        # Create line segments\n",
    "        if len(points_2d) >= 2:\n",
    "            lines.append(LineString(points_2d))\n",
    "    \n",
    "    if lines:\n",
    "        try:\n",
    "            # Create a MultiLineString\n",
    "            multi_line = MultiLineString(lines)\n",
    "            \n",
    "            # Merge connected line segments\n",
    "            merged = linemerge(multi_line)\n",
    "            \n",
    "            # Handle both single LineString and MultiLineString results\n",
    "            if isinstance(merged, LineString):\n",
    "                merged = [merged]\n",
    "            elif isinstance(merged, MultiLineString):\n",
    "                merged = list(merged.geoms)\n",
    "            \n",
    "            print(f\"Merged into {len(merged)} line groups\")\n",
    "            \n",
    "            # Try to close and fill each merged line group\n",
    "            for line in merged:\n",
    "                coords = np.array(line.coords)\n",
    "\n",
    "                patch = Polygon(coords, closed=True, facecolor='lightgray', \n",
    "                                edgecolor='none', alpha=0.4)\n",
    "                ax.add_patch(patch)\n",
    "                \n",
    "                # Draw the outline regardless\n",
    "                ax.plot(coords[:, 0], coords[:, 1], 'k-', linewidth=4, alpha=0.6)\n",
    "            \n",
    "            # Also try polygonize on the merged lines\n",
    "            polygons = list(polygonize(multi_line))\n",
    "            print(f\"Polygonize found {len(polygons)} polygons\")\n",
    "            \n",
    "            # for poly in polygons:\n",
    "            #     if poly.is_valid and poly.area > 1e-6:\n",
    "            #         coords = np.array(poly.exterior.coords)\n",
    "            #         patch = Polygon(coords, closed=True, facecolor='lightgray', \n",
    "            #                        edgecolor='none', alpha=0.4)\n",
    "            #         ax.add_patch(patch)\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            # Fallback: just draw the lines\n",
    "            for line in lines:\n",
    "                coords = np.array(line.coords)\n",
    "                ax.plot(coords[:, 0], coords[:, 1], 'k-', linewidth=4, alpha=0.5)\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# Add PyVista glyphs (field vectors) to matplotlib\n",
    "# ----------------------------------------------------\n",
    "# Extract arrow/vector data from glyphs\n",
    "if hasattr(glyphs, 'points') and glyphs.n_points > 0:\n",
    "    # Get start and end points of vectors\n",
    "    points = glyphs.points\n",
    "\n",
    "    # If glyphs are already arrow meshes, extract line segments\n",
    "    for i in range(glyphs.n_cells):\n",
    "        cell = glyphs.get_cell(i)\n",
    "        points_cell = cell.points\n",
    "        ax.plot(points_cell[:, 0], points_cell[:, 2], '-', linewidth=0.8, alpha=0.5, color=\"gray\")\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# Plot particle tracks\n",
    "# ----------------------------------------------------\n",
    "\n",
    "for eventIN in [2865, 10297]: #[99944,17]: 882\n",
    "    # plot different particles as diffent colors\n",
    "    eventdf = df_onlysolarwind[df_onlysolarwind[\"Event_Number\"]==eventIN]\n",
    "    e_eventdf = eventdf[eventdf[\"Particle_Type\"] == \"e-\"]\n",
    "\n",
    "    # Correct physical interleaving\n",
    "    e_interwoven = np.empty((np.vstack(e_eventdf[\"Pre_Step_Position_mm\"]).shape[0] + np.vstack(e_eventdf[\"Post_Step_Position_mm\"]).shape[0], 3))\n",
    "    e_interwoven[0::2] = np.vstack(e_eventdf[\"Pre_Step_Position_mm\"])\n",
    "    e_interwoven[1::2] = np.vstack(e_eventdf[\"Post_Step_Position_mm\"])\n",
    "\n",
    "    u, idx = np.unique(e_interwoven, axis=0, return_index=True)\n",
    "    e_interwoven = e_interwoven[np.sort(idx)]\n",
    "\n",
    "    ax.plot(e_interwoven[:2, 0], e_interwoven[:2,2], '-', color='blue', alpha=0.8,lw=5)\n",
    "    ax.plot(e_interwoven[:, 0], e_interwoven[:,2], '-', markersize=10, color='blue',alpha=0.8,lw=5)\n",
    "\n",
    "ax.set_ylim([-0.2+0.030, 0.22])\n",
    "#ax.set_xlim([-0.2, 0.2])\n",
    "ax.set_aspect('equal')\n",
    "ax.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"figures/SW_electron_event_demo_with_fields.svg\", transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyvista-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
