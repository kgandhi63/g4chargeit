{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.constants import epsilon_0, e as q_e\n",
    "from scipy.interpolate import griddata\n",
    "\n",
    "\n",
    "from matplotlib.colors import LogNorm\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colorbar import ColorbarBase\n",
    "from matplotlib.colors import Normalize\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.collections import LineCollection\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "\n",
    "import trimesh\n",
    "from trimesh.points import PointCloud\n",
    "\n",
    "from common_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_spheres = trimesh.load_mesh('../sphere-charging/geometry/stacked_spheres_frompython.stl') \n",
    "\n",
    "# get a single cross section of the mesh\n",
    "section = stacked_spheres.section(plane_origin=stacked_spheres.centroid, plane_normal=[0, 1, 0])\n",
    "slice_2D, to_3D = section.to_2D()\n",
    "slice_2D.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "configIN = \"onlysolarwind\"\n",
    "filenames = sorted(glob.glob(f\"../build-10um-uniform/fieldmaps/*107*{configIN}*.txt\"))\n",
    "print(filenames)\n",
    "\n",
    "# Usage\n",
    "df_uniform_iteration1  = read_uniform_fieldmap(filenames[0])\n",
    "if \"E_mag\" not in df_uniform_iteration1.columns:\n",
    "    df_uniform_iteration1[\"E_mag\"] = np.linalg.norm(df_uniform_iteration1[[\"Ex\", \"Ey\", \"Ez\"]].values, axis=1)\n",
    "\n",
    "max(df_uniform_iteration1[\"E_mag\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "configIN = \"onlysolarwind\"\n",
    "filenames = sorted(glob.glob(f\"../build-adaptive-mesh/fieldmaps/*113*{configIN}*.txt\"))\n",
    "\n",
    "# Usage\n",
    "df_adaptive_iteration1, metadata  = read_adaptive_fieldmap(filenames[0])\n",
    "if \"E_mag\" not in df_adaptive_iteration1.columns:\n",
    "    df_adaptive_iteration1[\"E_mag\"] = np.linalg.norm(df_adaptive_iteration1[[\"Ex\", \"Ey\", \"Ez\"]].values, axis=1)\n",
    "\n",
    "max(df_adaptive_iteration1[\"E_mag\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the distribution of the field to get a sense for the overall field values before analyzing the field in detail\n",
    "plt.hist(df_uniform_iteration1[df_uniform_iteration1[\"E_mag\"]>0][\"E_mag\"],bins=np.logspace(0,8,100),alpha=0.8,label=\"Uniform - 10 um\")\n",
    "plt.hist(df_adaptive_iteration1[df_adaptive_iteration1[\"E_mag\"]>0][\"E_mag\"],bins=np.logspace(0,8,100),alpha=0.2,label=\"Adaptive Mesh\")\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"|E| (V/m)\")\n",
    "plt.ylabel(\"Counts\")\n",
    "plt.title(\"Iteration 1\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_adaptive_iteration1[df_adaptive_iteration1[\"E_mag\"]>1e3][\"E_mag\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "max(df_uniform_iteration1[\"E_mag\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_spheres_cropped = stacked_spheres.copy()\n",
    "\n",
    "bbox_min = np.array([-0.2, -0.3, 0])\n",
    "bbox_max = np.array([ 0.2,  0.1,  100])\n",
    "\n",
    "# Filter vertices\n",
    "in_box = np.all((stacked_spheres_cropped.vertices >= bbox_min) & \n",
    "                (stacked_spheres_cropped.vertices <= bbox_max), axis=1)\n",
    "\n",
    "# Get face indices where all 3 vertices are in the box\n",
    "face_mask = np.all(in_box[stacked_spheres_cropped.faces], axis=1)\n",
    "\n",
    "# Extract submesh\n",
    "stacked_spheres_cropped = stacked_spheres_cropped.submesh([face_mask], only_watertight=False, append=True)\n",
    "\n",
    "# Usage with black semi-transparent edges\n",
    "scene = plot_trimesh_edges_only(stacked_spheres_cropped, edge_color=[0, 0, 0, 350])  # Black, 50% transparent\n",
    "\n",
    "# Create a PointCloud object\n",
    "#gamma_photoemission_sites = trimesh.points.PointCloud(np.array(all_gamma_holes_df[\"Pre_Step_Position_mm\"].tolist()), colors=[0, 255, 0, 255])  # RGBA green points\n",
    "iterationIN = 2\n",
    "fieldIN = df_adaptive_iteration1\n",
    "threshold = 1e2\n",
    "largefieldpoints = np.array(fieldIN[fieldIN[\"E_mag\"] > threshold][[\"x\", \"y\", \"z\"]].to_numpy().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# fieldpoints = []\n",
    "\n",
    "# for pointIN in largefieldpoints:\n",
    "#     sphere = trimesh.creation.icosphere(radius=0.005)  # Create a sphere for each point\n",
    "    \n",
    "#     # Apply translation to the sphere (move it to the position of the point)\n",
    "#     sphere.apply_translation(np.array(pointIN))\n",
    "    \n",
    "#     # Set the sphere color to red\n",
    "#     sphere.visual.face_colors = [255, 0, 0, 255]  # red spheres\n",
    "    \n",
    "#     # Append the sphere to the list\n",
    "#     fieldpoints.append(sphere)\n",
    "\n",
    "# # Add all the spheres to the scene\n",
    "# scene.add_geometry(fieldpoints)\n",
    "\n",
    "max_arrows = 3000\n",
    "field_largevalues = fieldIN[fieldIN[\"E_mag\"] > threshold]\n",
    "field_plot = field_largevalues.sample(n=max_arrows, random_state=42) if len(field_largevalues) > max_arrows else field_largevalues\n",
    "\n",
    "directions = field_plot[['Ex', 'Ey', 'Ez']].values\n",
    "magnitudes = np.linalg.norm(directions, axis=1)\n",
    "directions_unit = np.where(magnitudes[:, None] > 0, directions / magnitudes[:, None], 0)\n",
    "\n",
    "# Avoid log(0) by adding a small value (e.g., 1e-12) if needed\n",
    "log_magnitudes = np.log10(magnitudes + 1e-12)  # Log base 10 normalization\n",
    "\n",
    "# Normalize log-magnitudes to [0, 1]\n",
    "norm_magnitudes = (log_magnitudes - log_magnitudes.min()) / (np.ptp(log_magnitudes) + 1e-12)\n",
    "\n",
    "# Create a colormap\n",
    "cmap = plt.cm.jet\n",
    "colors_rgba = cmap(norm_magnitudes)  # shape: (N, 4) with floats in [0, 1]\n",
    "\n",
    "# Convert to 0–255 uint8 for trimesh\n",
    "colors_rgba = (colors_rgba * 255).astype(np.uint8)\n",
    "\n",
    "# Define base dimensions\n",
    "base_arrow_length = 0.05  # This will be scaled by magnitude\n",
    "arrow_radius = 0.001\n",
    "cone_ratio = 0.2  # Cone length as fraction of total arrow length\n",
    "\n",
    "# Normalize magnitudes for scaling arrow lengths\n",
    "scaling_factor = 0.5  # Adjust this to control overall arrow size\n",
    "scaled_lengths = base_arrow_length * scaling_factor * norm_magnitudes\n",
    "\n",
    "for pos, dir_vec, color, magnitude_norm, scaled_length in zip(\n",
    "    field_plot[['x', 'y', 'z']].values, \n",
    "    directions_unit, \n",
    "    colors_rgba, \n",
    "    norm_magnitudes,\n",
    "    scaled_lengths\n",
    "):\n",
    "    if np.linalg.norm(dir_vec) == 0:\n",
    "        continue\n",
    "\n",
    "    # Calculate arrow dimensions based on scaled length\n",
    "    arrow_length = scaled_length\n",
    "    cone_length = arrow_length * cone_ratio\n",
    "    shaft_length = arrow_length - cone_length\n",
    "\n",
    "    # Skip very small arrows to avoid visualization issues\n",
    "    # if arrow_length < 1e-4:\n",
    "    #     continue\n",
    "\n",
    "    # Create shaft - centered at origin along Z-axis\n",
    "    shaft = trimesh.creation.cylinder(radius=arrow_radius, height=shaft_length, sections=12)\n",
    "    shaft.apply_translation([0, 0, shaft_length / 2])  # Move so base is at z=0, top at z=shaft_length\n",
    "\n",
    "    # Create cone - positioned to touch the shaft\n",
    "    cone = trimesh.creation.cone(radius=arrow_radius * 2, height=cone_length, sections=12)\n",
    "    # Position cone so its base touches the top of the shaft (at z=shaft_length)\n",
    "    cone.apply_translation([0, 0, shaft_length])\n",
    "\n",
    "    # Combine parts\n",
    "    arrow = trimesh.util.concatenate([shaft, cone])\n",
    "\n",
    "    # Set color per face\n",
    "    arrow.visual.face_colors = np.tile(color, (arrow.faces.shape[0], 1))\n",
    "\n",
    "    # Align +Z to direction\n",
    "    transform = trimesh.geometry.align_vectors([0, 0, 1], dir_vec)\n",
    "    transform[:3, 3] = pos\n",
    "    arrow.apply_transform(transform)\n",
    "\n",
    "    scene.add_geometry(arrow)\n",
    "\n",
    "scene.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "## determine appropiate grid spacing for Electric Field calculations\n",
    "\n",
    "# Flatten the mesh grid to create sampling points\n",
    "sampling_points = np.column_stack([np.array(df[\"x\"]),np.array(df[\"y\"]),np.array(df[\"z\"])])\n",
    "print(len(sampling_points))\n",
    "adaptive_grid_points = trimesh.points.PointCloud(sampling_points, colors=[0, 255, 0, 255])\n",
    "\n",
    "scene = plot_trimesh_edges_only(stacked_spheres, edge_color=[0, 0, 0, 128])\n",
    "scene.add_geometry([adaptive_grid_points])\n",
    "scene.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "fileIN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## Case 1: SW electrons and ions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = \"../build-adaptive-mesh/root/\"\n",
    "configIN = \"solarwind\"\n",
    "filelist = sorted(glob.glob(f\"{directory_path}/*stackediteration*{configIN}*num100000.root\"))\n",
    "\n",
    "all_incident_protons_inside, all_incident_electrons_inside = [],[]\n",
    "\n",
    "for fileIN in filelist:\n",
    "\n",
    "    print(fileIN.split(\"/\")[-1])\n",
    "    number_str = fileIN.split(\"/\")[-1].split(\"_\")[1]\n",
    "    iterationNUM = int(''.join(filter(str.isdigit, number_str)))\n",
    "\n",
    "    if iterationNUM > 28:\n",
    "        break\n",
    "\n",
    "    # read data from different iterations\n",
    "    vars()[\"protons_inside_\"+str(number_str)], vars()[\"electrons_inside_\"+str(number_str)] = calculate_stats(read_rootfile(fileIN.split(\"/\")[-1], directory_path=directory_path), \n",
    "                                                                                                             config=configIN)\n",
    "    all_incident_protons_inside.append(vars()[\"protons_inside_\"+str(number_str)])\n",
    "    all_incident_electrons_inside.append(vars()[\"electrons_inside_\"+str(number_str)])\n",
    "    print(78*\"-\")\n",
    "\n",
    "# Concatenate all iterations into single DataFrames\n",
    "all_incident_protons_inside_df = pd.concat(all_incident_protons_inside, ignore_index=True)\n",
    "all_incident_electrons_inside_df = pd.concat(all_incident_electrons_inside, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all iterations into single DataFrames\n",
    "all_incident_protons_inside_df = pd.concat(all_incident_protons_inside, ignore_index=True)\n",
    "all_incident_electrons_inside_df = pd.concat(all_incident_electrons_inside, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "protons_inside_stackediteration0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "surf, ilm_values = plot_face_illumination(all_incident_protons_inside_df, stacked_spheres, vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(ilm_values, bins=np.logspace(-1,3,100))\n",
    "plt.xscale(\"log\")\n",
    "plt.title(\"# of Photons hitting each Voxel\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"Distribution Stats: mean {np.mean(ilm_values[ilm_values!=0])}, median {np.median(ilm_values[ilm_values!=0])}, max {np.max(ilm_values)}\")\n",
    "\n",
    "# our area is a factor of 4 smaller than their area \n",
    "print(f\"for one iteration, median # of particles in each equivalently sized voxel is {np.median(ilm_values[ilm_values!=0])/4}\")\n",
    "voxel_area = 0.0004/(1000)**2 # rough area approximated from python (0.4 micron2)\n",
    "zimmerman_charge = 1*(1e-6) # C/m2\n",
    "zimmerman_electronnum = (zimmerman_charge/1.60217663e-19)*voxel_area\n",
    "print(f\"will take {zimmerman_electronnum/(np.max(ilm_values[ilm_values!=0])*4)} iterations at this rate to get to the photoemission flux ranges shown at 3 seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterationIN=0\n",
    "surface,facolors = plot_surface_potential_fornegativepositive_charge(all_incident_electrons_inside_df, all_incident_protons_inside_df, stacked_spheres, vmin=-10,vmax=10)\n",
    "\n",
    "plt.hist(facolors[facolors!=0],bins=50)\n",
    "plt.show()\n",
    "\n",
    "# Make sure each triangle has its own unique vertices\n",
    "surface_edited = surface.copy()\n",
    "surface_edited.unmerge_vertices()\n",
    "surface_edited.visual.vertex_colors = None\n",
    "surface_edited.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "31919"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define colormap and normalization\n",
    "cmap = plt.cm.seismic\n",
    "norm = Normalize(vmin=-0.2, vmax=0.2)\n",
    "\n",
    "# Create a figure and a single axis for the colorbar\n",
    "fig, ax = plt.subplots(figsize=(6, 1))\n",
    "fig.subplots_adjust(bottom=0.5)\n",
    "\n",
    "# Create the colorbar\n",
    "cb = ColorbarBase(ax, cmap=cmap, norm=norm, orientation='horizontal')\n",
    "cb.set_label('Surface Potential (mV)')  # Optional label\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox_min = np.array([-0.25, -0.31, 0])\n",
    "bbox_max = np.array([ 0.15,  0.1,  100])\n",
    "\n",
    "# Filter vertices\n",
    "in_box = np.all((surface_edited.vertices >= bbox_min) & \n",
    "                (surface_edited.vertices <= bbox_max), axis=1)\n",
    "\n",
    "# Get face indices where all 3 vertices are in the box\n",
    "face_mask = np.all(in_box[surface_edited.faces], axis=1)\n",
    "\n",
    "# Extract submesh\n",
    "cropped = surface_edited.submesh([face_mask], only_watertight=False, append=True)\n",
    "cropped.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "## Case 2: Photoemission (incident gammas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "configIN = \"onlyphotoemission\"\n",
    "directory_path = \"../build-adaptive-mesh/root/\"\n",
    "filelist = sorted(glob.glob(f\"{directory_path}/*stackediteration*{configIN}*num100000.root\"))\n",
    "\n",
    "all_gamma_holes = []\n",
    "all_electrons_inside = []\n",
    "\n",
    "for fileIN in filelist:\n",
    "    print(fileIN.split(\"/\")[-1])\n",
    "    number_str = fileIN.split(\"/\")[-1].split(\"_\")[1]\n",
    "    iterationNUM = int(''.join(filter(str.isdigit, number_str)))\n",
    "\n",
    "    # read data from different iterations\n",
    "    vars()[\"gamma_holes_\"+str(number_str)], _, vars()[\"electrons_inside_\"+str(number_str)] = calculate_stats(read_rootfile(fileIN.split(\"/\")[-1], directory_path=directory_path),\n",
    "                                                                                                             config=configIN)\n",
    "    all_gamma_holes.append(vars()[\"gamma_holes_\"+str(number_str)])\n",
    "    all_electrons_inside.append(vars()[\"electrons_inside_\"+str(number_str)])\n",
    "    print(78*\"-\")\n",
    "\n",
    "# Concatenate all iterations into single DataFrames\n",
    "all_gamma_holes_df = pd.concat(all_gamma_holes, ignore_index=True)\n",
    "all_electrons_inside_df = pd.concat(all_electrons_inside, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_holes_stackediteration0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "surf, ilm_values = plot_face_illumination(gamma_holes_stackediteration0, stacked_spheres, vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(ilm_values, bins=np.logspace(-1,3,100))\n",
    "plt.xscale(\"log\")\n",
    "plt.title(\"# of Photons hitting each Voxel\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"Distribution Stats: mean {np.mean(ilm_values[ilm_values!=0])}, median {np.median(ilm_values[ilm_values!=0])}, max {np.max(ilm_values)}\")\n",
    "\n",
    "# our area is a factor of 4 smaller than their area \n",
    "print(f\"for one iteration, median # of particles in each equivalently sized voxel is {np.median(ilm_values[ilm_values!=0])/4}\")\n",
    "voxel_area = 0.0004/(1000)**2 # rough area approximated from python (0.4 micron2)\n",
    "zimmerman_charge = 0.5*(1e-6) # C/m2\n",
    "zimmerman_electronnum = (zimmerman_charge/1.60217663e-19)*voxel_area\n",
    "print(f\"will take {zimmerman_electronnum/(np.max(ilm_values[ilm_values!=0])/4)} iterations at this rate to get to the photoemission flux ranges shown at 3 seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 um \n",
    "configIN = \"onlysolarwind\"\n",
    "filenames = sorted(glob.glob(f\"../build-adaptive-mesh/fieldmaps/*{configIN}*.txt\"))\n",
    "\n",
    "for fileIN in filenames:\n",
    "\n",
    "    print(fileIN)\n",
    "    iterationIN = int(fileIN.split(\"-\")[-2]) #-50\n",
    "\n",
    "    if iterationIN > 0:\n",
    "\n",
    "        # Usage\n",
    "        vars()[\"field_\"+str(iterationIN)],_ = read_adaptive_fieldmap(fileIN)\n",
    "        vars()[\"field_\"+str(iterationIN)][\"E_mag\"]=np.linalg.norm(vars()[\"field_\"+str(iterationIN)][[\"Ex\", \"Ey\", \"Ez\"]].values, axis=1)\n",
    "\n",
    "        # plot the distribution of the field to get a sense for the overall field values before analyzing the field in detail\n",
    "        plt.hist(vars()[\"field_\"+str(iterationIN)][\"E_mag\"],bins=np.logspace(0,10,100))\n",
    "        plt.xscale(\"log\")\n",
    "        plt.yscale(\"log\")\n",
    "        plt.xlabel(\"|E| (V/m)\")\n",
    "        plt.ylabel(\"Counts\")\n",
    "        plt.title(\"field_\"+str(iterationIN))\n",
    "        plt.show()\n",
    "    \n",
    "    print(72*\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_spheres_cropped = stacked_spheres.copy()\n",
    "\n",
    "bbox_min = np.array([-0.2, -0.3, 0])\n",
    "bbox_max = np.array([ 0.2,  0.1,  100])\n",
    "\n",
    "# Filter vertices\n",
    "in_box = np.all((stacked_spheres_cropped.vertices >= bbox_min) & \n",
    "                (stacked_spheres_cropped.vertices <= bbox_max), axis=1)\n",
    "\n",
    "# Get face indices where all 3 vertices are in the box\n",
    "face_mask = np.all(in_box[stacked_spheres_cropped.faces], axis=1)\n",
    "\n",
    "# Extract submesh\n",
    "stacked_spheres_cropped = stacked_spheres_cropped.submesh([face_mask], only_watertight=False, append=True)\n",
    "\n",
    "# Usage with black semi-transparent edges\n",
    "scene = plot_trimesh_edges_only(stacked_spheres_cropped, edge_color=[0, 0, 0, 350])  # Black, 50% transparent\n",
    "\n",
    "# Create a PointCloud object\n",
    "#gamma_photoemission_sites = trimesh.points.PointCloud(np.array(all_gamma_holes_df[\"Pre_Step_Position_mm\"].tolist()), colors=[0, 255, 0, 255])  # RGBA green points\n",
    "iterationIN = 2\n",
    "fieldIN = vars()[\"field_\"+str(iterationIN)]\n",
    "largefieldpoints = np.array(fieldIN[fieldIN[\"E_mag\"] > 1e-5][[\"x\", \"y\", \"z\"]].to_numpy().tolist())\n",
    "\n",
    "# fieldpoints = []\n",
    "\n",
    "# for pointIN in largefieldpoints:\n",
    "#     sphere = trimesh.creation.icosphere(radius=0.005)  # Create a sphere for each point\n",
    "    \n",
    "#     # Apply translation to the sphere (move it to the position of the point)\n",
    "#     sphere.apply_translation(np.array(pointIN))\n",
    "    \n",
    "#     # Set the sphere color to red\n",
    "#     sphere.visual.face_colors = [255, 0, 0, 255]  # red spheres\n",
    "    \n",
    "#     # Append the sphere to the list\n",
    "#     fieldpoints.append(sphere)\n",
    "\n",
    "# # Add all the spheres to the scene\n",
    "# scene.add_geometry(fieldpoints)\n",
    "\n",
    "max_arrows = 3000\n",
    "field_nonzero = fieldIN[fieldIN[\"E_mag\"] > 1e-7]\n",
    "field_plot = field_nonzero.sample(n=max_arrows, random_state=42) if len(field_nonzero) > max_arrows else field_nonzero\n",
    "\n",
    "directions = field_plot[['Ex', 'Ey', 'Ez']].values\n",
    "magnitudes = np.linalg.norm(directions, axis=1)\n",
    "directions_unit = np.where(magnitudes[:, None] > 0, directions / magnitudes[:, None], 0)\n",
    "\n",
    "# Avoid log(0) by adding a small value (e.g., 1e-12) if needed\n",
    "log_magnitudes = np.log10(magnitudes + 1e-12)  # Log base 10 normalization\n",
    "\n",
    "# Normalize log-magnitudes to [0, 1]\n",
    "norm_magnitudes = (log_magnitudes - log_magnitudes.min()) / (np.ptp(log_magnitudes) + 1e-12)\n",
    "\n",
    "# Create a colormap\n",
    "cmap = plt.cm.jet\n",
    "colors_rgba = cmap(norm_magnitudes)  # shape: (N, 4) with floats in [0, 1]\n",
    "\n",
    "# Convert to 0–255 uint8 for trimesh\n",
    "colors_rgba = (colors_rgba * 255).astype(np.uint8)\n",
    "\n",
    "# Define base dimensions\n",
    "base_arrow_length = 0.05  # This will be scaled by magnitude\n",
    "arrow_radius = 0.001\n",
    "cone_ratio = 0.2  # Cone length as fraction of total arrow length\n",
    "\n",
    "# Normalize magnitudes for scaling arrow lengths\n",
    "scaling_factor = 1.0  # Adjust this to control overall arrow size\n",
    "scaled_lengths = base_arrow_length * scaling_factor * norm_magnitudes\n",
    "\n",
    "for pos, dir_vec, color, magnitude_norm, scaled_length in zip(\n",
    "    field_plot[['x', 'y', 'z']].values, \n",
    "    directions_unit, \n",
    "    colors_rgba, \n",
    "    norm_magnitudes,\n",
    "    scaled_lengths\n",
    "):\n",
    "    if np.linalg.norm(dir_vec) == 0:\n",
    "        continue\n",
    "\n",
    "    # Calculate arrow dimensions based on scaled length\n",
    "    arrow_length = scaled_length\n",
    "    cone_length = arrow_length * cone_ratio\n",
    "    shaft_length = arrow_length - cone_length\n",
    "\n",
    "    # Skip very small arrows to avoid visualization issues\n",
    "    # if arrow_length < 1e-4:\n",
    "    #     continue\n",
    "\n",
    "    # Create shaft - centered at origin along Z-axis\n",
    "    shaft = trimesh.creation.cylinder(radius=arrow_radius, height=shaft_length, sections=12)\n",
    "    shaft.apply_translation([0, 0, shaft_length / 2])  # Move so base is at z=0, top at z=shaft_length\n",
    "\n",
    "    # Create cone - positioned to touch the shaft\n",
    "    cone = trimesh.creation.cone(radius=arrow_radius * 2, height=cone_length, sections=12)\n",
    "    # Position cone so its base touches the top of the shaft (at z=shaft_length)\n",
    "    cone.apply_translation([0, 0, shaft_length])\n",
    "\n",
    "    # Combine parts\n",
    "    arrow = trimesh.util.concatenate([shaft, cone])\n",
    "\n",
    "    # Set color per face\n",
    "    arrow.visual.face_colors = np.tile(color, (arrow.faces.shape[0], 1))\n",
    "\n",
    "    # Align +Z to direction\n",
    "    transform = trimesh.geometry.align_vectors([0, 0, 1], dir_vec)\n",
    "    transform[:3, 3] = pos\n",
    "    arrow.apply_transform(transform)\n",
    "\n",
    "    scene.add_geometry(arrow)\n",
    "\n",
    "scene.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target point\n",
    "target = np.array([0.03, -0.1, 0.227]) \n",
    "#target = np.array([0, -0.1, 0.20700000000000002])\n",
    "\n",
    "# DataFrame to store results\n",
    "efield_values = []\n",
    "\n",
    "# Iterate over field_1, field_2, etc.\n",
    "for iterationIN in range(101, 118):\n",
    "    fieldIN = vars()[\"field_\" + str(iterationIN)]  # Field data for the current iteration\n",
    "\n",
    "    # Compute Euclidean distance to all points in the field\n",
    "    distances = np.linalg.norm(fieldIN[['x', 'y', 'z']].values - target, axis=1)\n",
    "\n",
    "    # Find index of the closest point\n",
    "    closest_idx = np.argmin(distances)\n",
    "\n",
    "    # Extract the closest point and its electric field\n",
    "    closest_idx = np.argmax(fieldIN[\"E_mag\"])\n",
    "    closest_point = fieldIN.iloc[closest_idx].copy()  # Explicitly make a copy to avoid SettingWithCopyWarning\n",
    "\n",
    "    # print(f\"Closest point for iteration {iterationIN}:\")\n",
    "    # print(closest_point[['x', 'y', 'z']])\n",
    "    # print(\"\\nElectric field at that point:\")\n",
    "    # print(closest_point[['Ex', 'Ey', 'Ez']])\n",
    "    \n",
    "    # Add iteration number\n",
    "    closest_point[\"iter\"] = iterationIN\n",
    "\n",
    "    # Append the result to the efield_values list\n",
    "    efield_values.append(closest_point[['iter', 'Ex', 'Ey', 'Ez']])\n",
    "\n",
    "# Create a new DataFrame from the efield_values list\n",
    "efield_df = pd.DataFrame(efield_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform linear fitting (degree 1 for linear)\n",
    "mag_values = efield_df[\"Ex\"] #np.linalg.norm(efield_df[[\"Ex\", \"Ey\", \"Ez\"]].values, axis=1) #efield_df[\"Ex\"]\n",
    "\n",
    "# Plot the original data\n",
    "plt.plot(efield_df[\"iter\"]-100, mag_values, '.-', label=\"Original Data\")\n",
    "\n",
    "# Labeling the plot\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(r\"E$_z$ (V/m)\")\n",
    "plt.ylabel(r\"|E| (V/m)\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Print the extrapolated value at x=50#print(f\"Extrapolated value at x = 50: {extrapolated_value:.2f} V/m\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "mag_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arraymag_values[0]/1e5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "94209+81883"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "136752+155429"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "After iteration 1 (total e-: 1139228, Holes:     870236)\n",
    "\n",
    "------------------------------------------\n",
    "After iteration 2 (total e-: 8,660)\n",
    "\n",
    "Closest point:\n",
    "x    0.000000\n",
    "y   -0.100000\n",
    "z    0.206795\n",
    "Name: 38481, dtype: float64\n",
    "\n",
    "Electric field at that point:\n",
    "Ex    1.360211e-07\n",
    "Ey    1.542312e-08\n",
    "Ez    8.020124e-08\n",
    "Name: 38481, dtype: float64\n",
    "\n",
    "------------------------------------------\n",
    "After iteration 1 (total e-: 4,356)\n",
    "\n",
    "Closest point:\n",
    "x    0.000000\n",
    "y   -0.100000\n",
    "z    0.206795\n",
    "Name: 4605855, dtype: float64\n",
    "\n",
    "Electric field at that point:\n",
    "Ex    8.230766e-08\n",
    "Ey   -5.993845e-09\n",
    "Ez    4.336823e-08\n",
    "Name: 4605855, dtype: float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the size of the world\n",
    "WorldX, WorldY, WorldZ = 200, 600, 606.61\n",
    "\n",
    "# think we need to get to ~8 iterations at 1 million particles each to get to 3s \n",
    "((4*1e-6*(WorldX*WorldY)/(1e6**2))*6.241509*10**18*3)/1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "1/1.60217663e-19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "voxel_area = 0.0004/(1000)**2 # rough area approximated from python (0.4 micron2)\n",
    "zimmerman_charge = 0.5*(1e-6) # C/m2\n",
    "(zimmerman_charge/1.60217663e-19)*voxel_area\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "voxel_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "385*1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "voxel_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"up through iteration 33\")\n",
    "surface,pot = plot_surface_potential_fornegativepositive_charge(all_electrons_inside_df, all_gamma_holes_df, stacked_spheres, vmin=-0.2,vmax=0.2)\n",
    "print(min(pot),max(pot))\n",
    "# Make sure each triangle has its own unique vertices\n",
    "surface_edited = surface.copy()\n",
    "surface_edited.unmerge_vertices()\n",
    "surface_edited.visual.vertex_colors = None\n",
    "surface_edited.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox_min = np.array([-0.2, -0.3, 0])\n",
    "bbox_max = np.array([ 0.2,  0.1,  100])\n",
    "\n",
    "# Filter vertices\n",
    "in_box = np.all((surface_edited.vertices >= bbox_min) & \n",
    "                (surface_edited.vertices <= bbox_max), axis=1)\n",
    "\n",
    "# Get face indices where all 3 vertices are in the box\n",
    "face_mask = np.all(in_box[surface_edited.faces], axis=1)\n",
    "\n",
    "# Extract submesh\n",
    "cropped = surface_edited.submesh([face_mask], only_watertight=False, append=True)\n",
    "cropped.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define colormap and normalization\n",
    "cmap = plt.cm.seismic\n",
    "norm = Normalize(vmin=-0.2, vmax=0.2)\n",
    "\n",
    "# Create a figure and a single axis for the colorbar\n",
    "fig, ax = plt.subplots(figsize=(4, 0.5))\n",
    "fig.subplots_adjust(bottom=0.5)\n",
    "\n",
    "# Create the colorbar\n",
    "cb = ColorbarBase(ax, cmap=cmap, norm=norm, orientation='horizontal')\n",
    "cb.set_label('Surface Potential (mV)')  # Optional label\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46",
   "metadata": {},
   "source": [
    "## Case 3: all particles (incident e-, protons, gammas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = \"../build-sphere-charging/root/\"\n",
    "configIN = \"allparticles\"\n",
    "filelist = sorted(glob.glob(f\"{directory_path}/*stackediteration*{configIN}*num5000.root\"))\n",
    "\n",
    "all_gamma_holes,all_photoemission_electrons,all_protons_inside,all_electrons_inside = [],[],[],[]\n",
    "\n",
    "for fileIN in filelist:\n",
    "    print(fileIN.split(\"/\")[-1])\n",
    "    number_str = fileIN.split(\"/\")[-1].split(\"_\")[1]\n",
    "    iterationNUM = int(''.join(filter(str.isdigit, number_str)))\n",
    "\n",
    "    # read data from different iterations\n",
    "    vars()[\"gamma_holes_\"+str(number_str)], vars()[\"photoemission_electrons_inside_\"+str(number_str)], \\\n",
    "        vars()[\"protons_inside_\"+str(number_str)], vars()[\"electrons_inside_\"+str(number_str)] = calculate_stats(read_rootfile(fileIN.split(\"/\")[-1], directory_path=directory_path), \\\n",
    "                                                                                                             config=configIN)\n",
    "    all_gamma_holes.append(vars()[\"gamma_holes_\"+str(number_str)])\n",
    "    all_photoemission_electrons.append(vars()[\"photoemission_electrons_inside_\"+str(number_str)])\n",
    "    all_protons_inside.append(vars()[\"protons_inside_\"+str(number_str)])\n",
    "    all_electrons_inside.append(vars()[\"electrons_inside_\"+str(number_str)])\n",
    "    print(78*\"-\")\n",
    "\n",
    "# Concatenate all iterations into single DataFrames\n",
    "all_gamma_holes_df = pd.concat(all_gamma_holes, ignore_index=True)\n",
    "all_photoemission_electrons_df = pd.concat(all_photoemission_electrons, ignore_index=True)\n",
    "all_protons_inside_df = pd.concat(all_protons_inside, ignore_index=True)\n",
    "all_electrons_inside_df = pd.concat(all_electrons_inside, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all iterations into single DataFrames\n",
    "all_gamma_holes_df = pd.concat(all_gamma_holes, ignore_index=True)\n",
    "all_photoemission_electrons_df = pd.concat(all_photoemission_electrons, ignore_index=True)\n",
    "all_protons_inside_df = pd.concat(all_protons_inside, ignore_index=True)\n",
    "all_electrons_inside_df = pd.concat(all_electrons_inside, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"up through iteration 28\")\n",
    "# input order: gammas, photoelectrons, protons, electrons, convex_combined,\n",
    "surface,facecolors = plot_surface_potential_allparticle_case(all_gamma_holes_df, all_photoemission_electrons_df, all_protons_inside_df, all_electrons_inside_df, \n",
    "                                                      stacked_spheres, vmin=-0.2,vmax=0.2)\n",
    "print(min(facecolors),max(facecolors))\n",
    "plt.plot(facecolors[facecolors!=0])\n",
    "plt.show()\n",
    "\n",
    "# Make sure each triangle has its own unique vertices\n",
    "surface_edited = surface.copy()\n",
    "surface_edited.unmerge_vertices()\n",
    "surface_edited.visual.vertex_colors = None\n",
    "surface_edited.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox_min = np.array([-0.2, -0.3, 0])\n",
    "bbox_max = np.array([ 0.2,  0.1,  100])\n",
    "\n",
    "# Filter vertices\n",
    "in_box = np.all((surface_edited.vertices >= bbox_min) & \n",
    "                (surface_edited.vertices <= bbox_max), axis=1)\n",
    "\n",
    "# Get face indices where all 3 vertices are in the box\n",
    "face_mask = np.all(in_box[surface_edited.faces], axis=1)\n",
    "\n",
    "# Extract submesh\n",
    "cropped = surface_edited.submesh([face_mask], only_watertight=False, append=True)\n",
    "cropped.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define colormap and normalization\n",
    "cmap = plt.cm.seismic\n",
    "norm = Normalize(vmin=-0.2, vmax=0.2)\n",
    "\n",
    "# Create a figure and a single axis for the colorbar\n",
    "fig, ax = plt.subplots(figsize=(4, 0.5))\n",
    "fig.subplots_adjust(bottom=0.5)\n",
    "\n",
    "# Create the colorbar\n",
    "cb = ColorbarBase(ax, cmap=cmap, norm=norm, orientation='horizontal')\n",
    "cb.set_label('Surface Potential (mV)')  # Optional label\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"up through iteration 19: only SW ions\")\n",
    "surface,facecolors = plot_surface_potential_fornegativepositive_charge(all_electrons_inside_df, all_protons_inside_df, stacked_spheres, vmin=-0.2,vmax=0.2)\n",
    "\n",
    "print(min(facecolors),max(facecolors))\n",
    "plt.plot(facecolors[facecolors!=0])\n",
    "plt.show()\n",
    "\n",
    "# Make sure each triangle has its own unique vertices\n",
    "surface_edited = surface.copy()\n",
    "surface_edited.unmerge_vertices()\n",
    "surface_edited.visual.vertex_colors = None\n",
    "surface_edited.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"up through iteration 22: only photons\")\n",
    "surface,facecolors = plot_surface_potential_fornegativepositive_charge(all_photoemission_electrons_df, all_gamma_holes_df, stacked_spheres, vmin=-0.5,vmax=0.5)\n",
    "\n",
    "print(min(facecolors),max(facecolors))\n",
    "plt.plot(facecolors[facecolors!=0])\n",
    "plt.show()\n",
    "\n",
    "# Make sure each triangle has its own unique vertices\n",
    "surface_edited = surface.copy()\n",
    "surface_edited.unmerge_vertices()\n",
    "surface_edited.visual.vertex_colors = None\n",
    "surface_edited.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox_min = np.array([-0.2, -0.3, 0])\n",
    "bbox_max = np.array([ 0.2,  0.1,  100])\n",
    "\n",
    "# Filter vertices\n",
    "in_box = np.all((surface_edited.vertices >= bbox_min) & \n",
    "                (surface_edited.vertices <= bbox_max), axis=1)\n",
    "\n",
    "# Get face indices where all 3 vertices are in the box\n",
    "face_mask = np.all(in_box[surface_edited.faces], axis=1)\n",
    "\n",
    "# Extract submesh\n",
    "cropped = surface_edited.submesh([face_mask], only_watertight=False, append=True)\n",
    "cropped.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geant4",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
