{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "\n",
    "import pyvista as pv\n",
    "pv.set_jupyter_backend('trame')  # or 'panel' if using panel\n",
    "\n",
    "from scipy.constants import epsilon_0, e as q_e\n",
    "from scipy.interpolate import griddata\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.spatial import cKDTree\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "# Import interpolate for numerical method\n",
    "from scipy.interpolate import CubicSpline\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "from matplotlib.colors import LogNorm\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colorbar import ColorbarBase\n",
    "from matplotlib.colors import Normalize\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.collections import LineCollection\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "import matplotlib as mpl\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor, as_completed\n",
    "\n",
    "import trimesh\n",
    "import h5py\n",
    "from trimesh.points import PointCloud\n",
    "\n",
    "from common_functions import *  # Assuming common_functions.py is in the same directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in geometry to get the offset \n",
    "geometryIN = \"stacked_spheres_frompython_cropped.stl\"\n",
    "geometry = trimesh.load_mesh(f'geometry/{geometryIN}') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## 2D Representation of the Electric Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration = 99\n",
    "\n",
    "configIN = \"onlyphotoemission\"\n",
    "#directory = \"/storage/scratch1/5/avira7/Grain-Charging-Simulation-Data/build-dissipationRefinedGrid-initial8max0.8final12/\"\n",
    "description = \"ZimmermanInitial8max0.8final11\"\n",
    "\n",
    "if iteration <10 :\n",
    "    filenames = sorted(glob.glob(f\"raw-files/{description}/*00{iteration}*{configIN}*.txt\")) #{iteration}\n",
    "else:\n",
    "    filenames = sorted(glob.glob(f\"raw-files/{description}/*{iteration}*{configIN}*.txt\")) #{iteration}\n",
    "print(filenames)\n",
    "\n",
    "df  = read_data_format_efficient(filenames,scaling=True)\n",
    "\n",
    "# check to make sure this matches the total nodes in outputlogs\n",
    "#len(df[iteration][\"E_mag\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SETTINGS HERE ARE OPTIMIZED FOR ITERATION 86 ##\n",
    "\n",
    "fieldIN = df[iteration]\n",
    "\n",
    "N_DOWNSAMPLE_EMAG = 1\n",
    "ARROW_VOXEL_SPACING = 0.02 \n",
    "Y_SLICE = 0.0 + geometry.centroid[1]  # This correctly uses the centroid's Y\n",
    "THICKNESS = 0.001\n",
    "VECTOR_SCALE_FACTOR = 1.5e-7\n",
    "FIELD_AVERAGE_RADIUS = 2.5e-3\n",
    "\n",
    "vmin, vmax = (-2e5, 2e5)\n",
    "red_point = np.array([-0.1, 0, 0.1 + 0.037]) + geometry.centroid\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# Voxel Downsampling Helper Function\n",
    "# ----------------------------------------------------\n",
    "def voxel_downsample_points(points, spacing):\n",
    "    \"\"\"\n",
    "    Selects one point per voxel defined by the spacing.\n",
    "    Assumes points are 3D, but only uses X and Z for 2D density control.\n",
    "    \"\"\"\n",
    "    min_x, _, min_z = points.min(axis=0)\n",
    "    \n",
    "    x_indices = np.floor((points[:, 0] - min_x) / spacing).astype(int)\n",
    "    z_indices = np.floor((points[:, 2] - min_z) / spacing).astype(int)\n",
    "    \n",
    "    max_x_index = x_indices.max() + 1\n",
    "    voxel_keys = z_indices * max_x_index + x_indices\n",
    "\n",
    "    _, unique_indices = np.unique(voxel_keys, return_index=True)\n",
    "    \n",
    "    return unique_indices\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# Step 0: Load, Filter, and Downsample Data\n",
    "# ----------------------------------------------------\n",
    "start_time = time.time()\n",
    "points = fieldIN[\"pos\"]\n",
    "vectors = fieldIN[\"E\"]\n",
    "magnitudes = fieldIN[\"E_mag\"]\n",
    "\n",
    "initial_mask = (points[:, 2] > 0) & (magnitudes > 0)\n",
    "points = points[initial_mask]\n",
    "vectors = vectors[initial_mask]\n",
    "magnitudes = magnitudes[initial_mask]\n",
    "\n",
    "points_ds = points[::N_DOWNSAMPLE_EMAG]\n",
    "vectors_ds = vectors[::N_DOWNSAMPLE_EMAG]\n",
    "magnitudes_ds = magnitudes[::N_DOWNSAMPLE_EMAG]\n",
    "\n",
    "point_cloud = pv.PolyData(points_ds)\n",
    "point_cloud[\"E_mag\"] = magnitudes_ds\n",
    "point_cloud[\"Ex_val\"] = vectors_ds[:,0]\n",
    "point_cloud[\"Ez_val\"] = vectors_ds[:,2]\n",
    "\n",
    "print(f\"Starting points (filtered by z > 0 & mag > 0): {len(points)}\")\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# Step 1: Geometry Setup and Slicing\n",
    "# ----------------------------------------------------\n",
    "start_time_geo = time.time()\n",
    "\n",
    "pv_spheres = pv.PolyData(\n",
    "    geometry.vertices,\n",
    "    np.hstack([np.full((len(geometry.faces), 1), 3), geometry.faces])\n",
    ").compute_normals()\n",
    "\n",
    "bbox_bounds = point_cloud.bounds\n",
    "bbox = pv.Box(bounds=bbox_bounds)\n",
    "pv_spheres_cropped = pv_spheres.clip_box(bbox, invert=False)\n",
    "\n",
    "normal = [0, 1, 0]\n",
    "\n",
    "# FIX: Use explicit center with Y_SLICE for the plane\n",
    "plane_center = [\n",
    "    (bbox_bounds[0] + bbox_bounds[1]) / 2,  # X center\n",
    "    Y_SLICE,                                  # Y at slice location\n",
    "    (bbox_bounds[4] + bbox_bounds[5]) / 2   # Z center\n",
    "]\n",
    "\n",
    "field_slice_mesh = pv.Plane(\n",
    "    center=plane_center,  # <-- FIXED: Use explicit center at Y_SLICE\n",
    "    direction=normal,\n",
    "    j_size=bbox_bounds[1] - bbox_bounds[0],\n",
    "    i_size=bbox_bounds[5] - bbox_bounds[4],\n",
    "    i_resolution=250, \n",
    "    j_resolution=250\n",
    ")\n",
    "\n",
    "field_slice_interpolated = field_slice_mesh.interpolate(\n",
    "    point_cloud,\n",
    "    sharpness=3.0,\n",
    "    radius=0.001,\n",
    "    null_value=1, \n",
    "    strategy='closest_point'\n",
    ")\n",
    "\n",
    "# Ensure all Y coordinates are exactly at Y_SLICE\n",
    "field_slice_interpolated.points[:, 1] = Y_SLICE\n",
    "\n",
    "# Slice geometry at the same location\n",
    "geo_slice = pv_spheres_cropped.slice(normal=normal, origin=plane_center)  # <-- FIXED: Use plane_center\n",
    "print(f\"Geometry and slicing preparation complete in {time.time() - start_time_geo:.2f}s\")\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# Step 2: Vector Field Glyphs (Arrows)\n",
    "# ----------------------------------------------------\n",
    "start_time_vectors = time.time()\n",
    "\n",
    "vector_mask = np.abs(points_ds[:, 1] - Y_SLICE) < THICKNESS\n",
    "points_slice_full = points_ds[vector_mask]\n",
    "vectors_slice_full = vectors_ds[vector_mask]\n",
    "magnitudes_slice_full = magnitudes_ds[vector_mask]\n",
    "\n",
    "unique_indices = voxel_downsample_points(points_slice_full, ARROW_VOXEL_SPACING)\n",
    "\n",
    "points_slice = points_slice_full[unique_indices]\n",
    "vectors_slice = vectors_slice_full[unique_indices]\n",
    "magnitudes_slice = magnitudes_slice_full[unique_indices]\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# ADD ONE MORE COLUMN ON THE RIGHT EDGE\n",
    "# ----------------------------------------------------\n",
    "# Find the maximum X value in the current slice\n",
    "max_x = points_slice[:, 0].max()\n",
    "\n",
    "# Find all Z values that exist at or near the max X\n",
    "x_threshold = max_x - ARROW_VOXEL_SPACING / 2  # Points in the rightmost column\n",
    "rightmost_mask = points_slice[:, 0] >= x_threshold\n",
    "\n",
    "# Get unique Z values from the rightmost column\n",
    "z_values_right = points_slice[rightmost_mask, 2]\n",
    "\n",
    "# Create new points one spacing to the right\n",
    "new_x = max_x + ARROW_VOXEL_SPACING\n",
    "new_points = np.array([[new_x, Y_SLICE - 2*THICKNESS, z] for z in z_values_right])\n",
    "\n",
    "# Interpolate field values at these new points from the nearest neighbors\n",
    "# Use the existing points to find nearest field values\n",
    "from scipy.spatial import cKDTree\n",
    "tree = cKDTree(points_slice_full[:, [0, 2]])  # Only use X and Z for 2D lookup\n",
    "distances, indices = tree.query(new_points[:, [0, 2]], k=1)\n",
    "new_vectors = vectors_slice_full[indices]\n",
    "new_magnitudes = magnitudes_slice_full[indices]\n",
    "\n",
    "# Append the new column to existing data\n",
    "points_slice = np.vstack([points_slice, new_points])\n",
    "vectors_slice = np.vstack([vectors_slice, new_vectors])\n",
    "magnitudes_slice = np.concatenate([magnitudes_slice, new_magnitudes])\n",
    "# ----------------------------------------------------\n",
    "\n",
    "MAGNITUDE_MAX_CLAMP = ARROW_VOXEL_SPACING / VECTOR_SCALE_FACTOR / 2\n",
    "magnitudes_slice_clamped = np.clip(magnitudes_slice, a_min=None, a_max=MAGNITUDE_MAX_CLAMP)\n",
    "\n",
    "points_slice[:,1] = Y_SLICE - 2*THICKNESS\n",
    "vectors_slice[:,1] = 0.0 - 2*THICKNESS\n",
    "slice_mesh_vectors = pv.PolyData(points_slice)\n",
    "slice_mesh_vectors['vectors'] = vectors_slice\n",
    "slice_mesh_vectors['magnitude'] = magnitudes_slice_clamped\n",
    "\n",
    "print(f\"Points in vector slice (after density control + extra column): {len(points_slice)}, old length: {len(points_slice_full)}...\")\n",
    "\n",
    "arrow = pv.Arrow(tip_length=0.3, tip_radius=0.2, shaft_radius=0.04)\n",
    "glyphs = slice_mesh_vectors.glyph(\n",
    "    orient='vectors',\n",
    "    scale='magnitude',\n",
    "    factor=VECTOR_SCALE_FACTOR,\n",
    "    geom=arrow\n",
    ")\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# Step 3: Visualization\n",
    "# ----------------------------------------------------\n",
    "pl = pv.Plotter()\n",
    "pl.set_background('white')\n",
    "\n",
    "pl.add_mesh(\n",
    "    field_slice_interpolated,\n",
    "    scalars=\"Ex_val\",\n",
    "    cmap=\"YlGnBu\",\n",
    "    opacity=1,\n",
    "    show_edges=False,\n",
    "    clim=[vmin, vmax],\n",
    "    scalar_bar_args={\n",
    "        'title': None,\n",
    "        'vertical': False,\n",
    "        'position_x': 0.20,\n",
    "        'position_y': 0.12,\n",
    "        'width': 0.6,\n",
    "        'height': 0.05,\n",
    "    }\n",
    ")\n",
    "\n",
    "pl.add_mesh(geo_slice, color=\"black\", line_width=3, opacity=0.5)\n",
    "pl.add_mesh(glyphs, color='black', show_scalar_bar=False, line_width=4, opacity=1)\n",
    "\n",
    "sphere = pv.Sphere(radius=FIELD_AVERAGE_RADIUS, center=red_point)\n",
    "pl.add_mesh(sphere, color=\"red\", opacity=1)\n",
    "\n",
    "pl.enable_parallel_projection()\n",
    "pl.enable_2d_style()\n",
    "pl.view_xz()\n",
    "\n",
    "pl.screenshot(f'figures/fieldvectors_{configIN}#{iteration}.jpeg', scale=4)\n",
    "\n",
    "print(f\"Total execution time: {time.time() - start_time:.2f}s\")\n",
    "pl.show(jupyter_backend='static')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------\n",
    "# Step 3: Visualization Setup\n",
    "# ----------------------------------------------------\n",
    "\n",
    "# Define visualization parameters\n",
    "FIELD_AVERAGE_RADIUS = 1e-3\n",
    "CIRCLE_RADIUS = 40/2/1000  # 20 µm converted to meter\n",
    "\n",
    "offsetLimitsX = 0.007\n",
    "offsetLimitsY = 0.0092\n",
    "new_step_x = offsetLimitsX   # 2 points in X\n",
    "new_step_y = offsetLimitsY   # 3 points in Y\n",
    "\n",
    "# Create grid of target points\n",
    "xoffset = np.round(np.arange(-offsetLimitsX, offsetLimitsX + 1e-9, new_step_x), 5)[0:2] #[1]\n",
    "yoffset = np.round(np.arange(-offsetLimitsY, offsetLimitsY + 1e-9, new_step_y), 5)\n",
    "X, Y = np.meshgrid(xoffset, yoffset)\n",
    "\n",
    "target_center = np.array([-0.1, 0, 0.1 + 0.037]) + geometry.centroid\n",
    "target_points_array = np.vstack([\n",
    "    target_center[0] - X.flatten(), \n",
    "    target_center[1] - np.zeros(len(X.flatten())), \n",
    "    target_center[2] - Y.flatten()\n",
    "]).T\n",
    "\n",
    "print(f\"Processing {len(target_points_array)} target points with radius {FIELD_AVERAGE_RADIUS*1000:.1f} mm\")\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# Create Plotter and Add Meshes\n",
    "# ----------------------------------------------------\n",
    "pl = pv.Plotter()\n",
    "pl.set_background('white')\n",
    "\n",
    "# Add interpolated field slice\n",
    "pl.add_mesh(\n",
    "    field_slice_interpolated,\n",
    "    scalars=\"Ex_val\",\n",
    "    cmap=\"YlGnBu\",\n",
    "    opacity=1,\n",
    "    show_edges=False,\n",
    "    clim=[vmin, vmax],\n",
    "    scalar_bar_args={\n",
    "        'title': None,\n",
    "        'vertical': False,\n",
    "        'position_x': 0.20,\n",
    "        'position_y': 0.12,\n",
    "        'width': 0.6,\n",
    "        'height': 0.05,\n",
    "    }\n",
    ")\n",
    "\n",
    "# Add geometry outline\n",
    "pl.add_mesh(geo_slice, color=\"black\", line_width=5, opacity=0.5)\n",
    "\n",
    "# Add vector field arrows\n",
    "pl.add_mesh(glyphs, color='black', show_scalar_bar=False, line_width=4, opacity=1)\n",
    "\n",
    "# Color Map Setup\n",
    "CMAP_NAME = 'jet'\n",
    "n_targets = len(target_points_array)\n",
    "discrete_cmap = plt.get_cmap(CMAP_NAME, n_targets + 1)\n",
    "color_list_rgba = [discrete_cmap(i) for i in np.linspace(0, 1, n_targets + 1)]\n",
    "\n",
    "# Add target point spheres\n",
    "for target_point, colorIN in zip(target_points_array,color_list_rgba):\n",
    "    sphere = pv.Sphere(radius=FIELD_AVERAGE_RADIUS, center=target_point)\n",
    "    pl.add_mesh(sphere, color=colorIN, opacity=1)\n",
    "\n",
    "# # Add reference circle at center (in XZ plane)\n",
    "theta = np.linspace(0, 2 * np.pi, 100)\n",
    "circle_points = np.column_stack([\n",
    "    target_center[0] + CIRCLE_RADIUS * np.cos(theta),\n",
    "    np.full_like(theta, target_center[1]),\n",
    "    target_center[2] + CIRCLE_RADIUS * np.sin(theta)\n",
    "])\n",
    "polyline = pv.PolyData(circle_points)\n",
    "pl.add_mesh(polyline, color='k', point_size=0.5, opacity=0.8) # Add to the plot\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# Camera Setup and Render\n",
    "# ----------------------------------------------------\n",
    "pl.enable_parallel_projection()\n",
    "pl.enable_2d_style()\n",
    "pl.view_xz()\n",
    "\n",
    "print(f\"Total execution time: {time.time() - start_time:.2f}s\")\n",
    "pl.show(jupyter_backend='static')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable LaTeX rendering\n",
    "mpl.rcParams['text.usetex'] = False\n",
    "# Set the global font size\n",
    "mpl.rcParams.update({'font.size': 16})\n",
    "\n",
    "cmap = plt.cm.YlGnBu \n",
    "vmin, vmax = (-2e5, 2e5) # in log(E_mag) units\n",
    "norm = mpl.colors.Normalize(vmin=vmin, vmax=vmax)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 0.1))\n",
    "\n",
    "# --- 1. Create and Configure the ScalarFormatter ---\n",
    "formatter = ticker.ScalarFormatter(useMathText=True)\n",
    "\n",
    "formatter.set_useOffset(False) \n",
    "formatter.set_powerlimits((0, 0)) \n",
    "\n",
    "# --- 2. Create the Colorbar and apply the Formatter ---\n",
    "cb = mpl.colorbar.ColorbarBase(\n",
    "    ax, \n",
    "    cmap=cmap, \n",
    "    norm=norm, \n",
    "    orientation='horizontal', label=r\"E$_x$ (V/m)\"\n",
    ")\n",
    "\n",
    "# Apply the formatter to the colorbar's x-axis\n",
    "cb.ax.xaxis.set_major_formatter(formatter)\n",
    "\n",
    "# --- 3. Display the Plot ---\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## Quantitative Comparison with Zimmerman et al. 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test one file \n",
    "\n",
    "# directory = \"processed-fieldmaps/\"\n",
    "# processedResults = load_h5_to_dict(f\"{directory}/PE_425K_initial8max0.8final11_RefinedGridDissipation_sphere40um_adjustedworld_through2X.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- configuration ---\n",
    "directory = \"processed-fieldmaps/\"\n",
    "h5_filenames = glob.glob(f\"{directory}/*425K*.h5\")\n",
    "\n",
    "FIELD_AVERAGE_RADIUS = 1e-3\n",
    "CIRCLE_RADIUS = 40/2/1000  # 20 µm converted to meter\n",
    "\n",
    "offsetLimitsX = 0.007\n",
    "offsetLimitsY = 0.0092\n",
    "new_step_x = offsetLimitsX   # 2 points in X\n",
    "new_step_y = offsetLimitsY   # 3 points in Y\n",
    "\n",
    "# Create grid of target points\n",
    "xoffset = np.round(np.arange(-offsetLimitsX, offsetLimitsX + 1e-9, new_step_x), 5)[1] #[0:2] #[1]\n",
    "yoffset = np.round(np.arange(-offsetLimitsY, offsetLimitsY + 1e-9, new_step_y), 5)[1] \n",
    "\n",
    "X, Y = np.meshgrid(xoffset, yoffset)\n",
    "\n",
    "target_center =  np.array([-0.1, 0, 0.1 + 0.037]) + geometry.centroid\n",
    "target_points_array = np.vstack([\n",
    "    target_center[0] - X.flatten(), \n",
    "    target_center[1] - np.zeros(len(X.flatten())), \n",
    "    target_center[2] - Y.flatten()\n",
    "]).T \n",
    "\n",
    "if len(target_points_array) == 1: print(f\"Processing target point at {target_points_array} with radius {FIELD_AVERAGE_RADIUS*1000} um\")\n",
    "else: print(f\"Processing {len(target_points_array)} target points with radius {FIELD_AVERAGE_RADIUS*1000} um\")\n",
    "\n",
    "# --- helper function for one key and one target point ---\n",
    "def process_key_target(keyIN, val, target_point, radius):\n",
    "    points = val[\"pos\"]\n",
    "    vectors = val[\"E\"]\n",
    "    magnitudes = val[\"E_mag\"]\n",
    "    \n",
    "    # Mask for spherical averaging around target point\n",
    "    mask = np.sum((points - target_point)**2, axis=1) <= radius**2\n",
    "    \n",
    "    if not np.any(mask):\n",
    "        # Return placeholders if no points in sphere\n",
    "        return -1, np.full(3, np.nan), np.nan, np.full(3, np.nan), 0\n",
    "\n",
    "    avg_position = points[mask].mean(axis=0)\n",
    "    E_vec = vectors[mask].mean(axis=0)\n",
    "    E_mag = magnitudes[mask].mean(axis=0)\n",
    "    E_vec_errors = vectors[mask].std(axis=0) / np.sqrt(len(magnitudes[mask]))\n",
    "    \n",
    "    return int(keyIN.split(\"_\")[1]), E_vec, E_mag, avg_position, len(magnitudes[mask])\n",
    "\n",
    "# --- extract metadata from filename ---\n",
    "def parse_filename_metadata(filename):\n",
    "    \"\"\"\n",
    "    Processes files and extracts metadata.\n",
    "    Example:\n",
    "    PE_425K_initial8max0.8final12_RefinedGridDissipation_500000particles_Sphere20um_pos-0.1_through26.h5\n",
    "    \"\"\"\n",
    "\n",
    "    base = os.path.basename(filename)\n",
    "    case = base.split(\"_\")[0]\n",
    "\n",
    "    # Temperature\n",
    "    temp_match = re.search(r'_(\\d+)K_', base)\n",
    "    temperature = int(temp_match.group(1)) if temp_match else np.nan\n",
    "\n",
    "    # Position\n",
    "    pos_match = re.search(r'_pos([-+]?\\d*\\.?\\d+)_through', base)\n",
    "    pos_value = float(pos_match.group(1)) if pos_match else np.nan\n",
    "\n",
    "    # Sphere size (if any)\n",
    "    sphere_match = re.search(r'_sphere(\\d+)um', base, re.IGNORECASE)\n",
    "    sphere_um = int(sphere_match.group(1)) if sphere_match else np.nan\n",
    "\n",
    "    # Octree parameters: initial, grad threshold, final\n",
    "    octree_match = re.search(r'_initial(\\d+)max([-+]?\\d*\\.?\\d+)final(\\d+)', base)\n",
    "    if octree_match:\n",
    "        octree_params = {\n",
    "            \"initial_depth\": int(octree_match.group(1)),\n",
    "            \"percent_gradThreshold\": float(octree_match.group(2)),\n",
    "            \"final_depth\": int(octree_match.group(3))\n",
    "        }\n",
    "    else:\n",
    "        octree_params = {\"initial_depth\": np.nan, \"grad_threshold\": np.nan, \"final_depth\": np.nan}\n",
    "\n",
    "    metadata = {\n",
    "        \"filename\": base,\n",
    "        \"case\": case,\n",
    "        \"temperature\": temperature,\n",
    "        \"sphere_um\": sphere_um,\n",
    "        \"octree\": octree_params,\n",
    "    }\n",
    "\n",
    "    return metadata\n",
    "\n",
    "\n",
    "# --- worker for one file ---\n",
    "def process_file(fileIN):\n",
    "    metadata = parse_filename_metadata(fileIN)\n",
    "\n",
    "    if metadata is None:\n",
    "        return None\n",
    "\n",
    "    print(f\"→ Started {os.path.basename(fileIN)}\\n\", flush=True)\n",
    "    processedResults = load_h5_to_dict(fileIN)\n",
    "    key_prefix = os.path.basename(fileIN).split('_through')[0]\n",
    "\n",
    "    keys = list(processedResults.keys())\n",
    "\n",
    "    # Dictionary to hold results for each target point\n",
    "    target_point_results = {}\n",
    "\n",
    "    # Process each target point\n",
    "    for tp_idx, target_point in enumerate(target_points_array):\n",
    "        tp_key = f\"target_{tp_idx:04d}\"\n",
    "        \n",
    "        # --- sequential processing across keys for this target point ---\n",
    "        results = []\n",
    "        for k in keys:\n",
    "            result = process_key_target(k, processedResults[k], target_point, FIELD_AVERAGE_RADIUS)\n",
    "            results.append(result)\n",
    "\n",
    "        ids, E_vecs, E_mags, standard_errors, N = zip(*results)\n",
    "        ids = np.array(ids)\n",
    "        E_vecs = np.array(E_vecs)\n",
    "        E_mags = np.array(E_mags)\n",
    "        standard_errors = np.array(standard_errors)\n",
    "        num_points = np.array(N)\n",
    "\n",
    "        target_point_results[tp_key] = {\n",
    "            \"iter\": ids,\n",
    "            \"E_vecs\": E_vecs,\n",
    "            \"E_mags\": E_mags,\n",
    "            \"point_errors\": standard_errors,\n",
    "            \"N\": num_points,\n",
    "            \"target_point\": target_point,\n",
    "            \"radius\": FIELD_AVERAGE_RADIUS\n",
    "        }\n",
    "        \n",
    "        if (tp_idx + 1) % 10 == 0:\n",
    "            print(f\"  Processed {tp_idx + 1}/{len(target_points_array)} target points\", flush=True)\n",
    "\n",
    "    return key_prefix, {\n",
    "        \"target_points\": target_point_results,\n",
    "        \"metadata\": metadata\n",
    "    }\n",
    "\n",
    "# --- sequential execution across files ---\n",
    "all_processed = {}\n",
    "\n",
    "for fileIN in h5_filenames:\n",
    "    try:\n",
    "        result = process_file(fileIN)\n",
    "        if result is not None:\n",
    "            key_prefix, data = result\n",
    "            all_processed[key_prefix] = data\n",
    "            print(f\"✔ Finished {os.path.basename(fileIN)}\\n\", flush=True)\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error in {os.path.basename(fileIN)}: {e}\\n\", flush=True)\n",
    "\n",
    "print(f\"\\n=== Processing Complete ===\")\n",
    "print(f\"Total files processed: {len(all_processed)}\")\n",
    "print(f\"Target points per file: {len(target_points_array)}\")\n",
    "\n",
    "# --- Access results example ---\n",
    "# all_processed[key_prefix][\"target_points\"][\"target_0000\"][\"E_vecs\"]\n",
    "# all_processed[key_prefix][\"target_points\"][\"target_0000\"][\"target_point\"]\n",
    "# all_processed[key_prefix][\"metadata\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable LaTeX rendering\n",
    "mpl.rcParams['text.usetex'] = False\n",
    "# Set the global font size\n",
    "mpl.rcParams.update({'font.size': 14})\n",
    "\n",
    "# select one key for multiple target points\n",
    "KEY_TARGET_MULTI = 'PE_425K_initial8max0.8final11_noDissipation_sphere40um_pos-0.1' #'SW_425K_initial8max0.8final10_RefinedGridDissipation_sphere40um_pos-0.1' # 'SW_425K_initial8max0.8final11_RefinedGridDissipation_sphere40um_pos-0.1'\n",
    "\n",
    "# Load external literature data\n",
    "zimmerman_SWdata = pd.read_csv(\"literature-data/Fig7a-SW.csv\")\n",
    "zimmerman_PEdata = pd.read_csv(\"literature-data/Fig7a-PE.csv\")\n",
    "zimmerman_PEandSWdata = pd.read_csv(\"literature-data/Fig7a-PE+SW.csv\")\n",
    "\n",
    "# Simulation Parameters (used for time conversion)\n",
    "WORLD_XY_AREA_SQ_M = 400 * 300 / (1e6**2)  # World area (m^2)\n",
    "PE_Ele_FLUX = 4e-6 * 6.241509e18\n",
    "SW_ION_FLUX = 3e-7 * 6.241509e18\n",
    "SW_Ele_FLUX = 1.5e-6 * 6.241509e18 # still dont know why the SW ele flux gives a difference conversion factor\n",
    "\n",
    "# PE Conversion Factor\n",
    "PARTICLES_PER_ITERATION_PE = 81775\n",
    "CONVERT_ITERATION_PE_TIME = PARTICLES_PER_ITERATION_PE / WORLD_XY_AREA_SQ_M / PE_Ele_FLUX\n",
    "\n",
    "# SW Conversion Factor\n",
    "PARTICLES_PER_ITERATION_SW = 14208\n",
    "CONVERT_ITERATION_SW_TIME = PARTICLES_PER_ITERATION_SW / WORLD_XY_AREA_SQ_M / SW_ION_FLUX\n",
    "\n",
    "# SW Conversion Factor\n",
    "PARTICLES_PER_ITERATION_All = 4452\n",
    "CONVERT_ITERATION_All_TIME = PARTICLES_PER_ITERATION_All / WORLD_XY_AREA_SQ_M / SW_ION_FLUX\n",
    "\n",
    "# --- 3. PLOTTING SETUP ---\n",
    "fig, ax_main = plt.subplots(figsize=(8.01, 4.6))\n",
    "\n",
    "# --- 4. PLOT LITERATURE DATA ---\n",
    "ax_main.plot(10**zimmerman_SWdata[\"x\"], zimmerman_SWdata[\" y\"], '-', color=\"k\", lw=3, alpha=0.3, label=None)\n",
    "ax_main.plot(10**zimmerman_PEdata[\"x\"], zimmerman_PEdata[\" y\"], '-', color=\"k\", lw=3, alpha=0.3, label=None)\n",
    "ax_main.plot(10**zimmerman_PEandSWdata[\"x\"], zimmerman_PEandSWdata[\" y\"], '--', color=\"k\", lw=3, alpha=0.3)\n",
    "\n",
    "# --- 5. PLOT SIMULATION DATA FOR EACH TARGET POINT OR FOR ALL CONFIGURATIONS ---\n",
    "\n",
    "if len(all_processed[list(all_processed.keys())[0]][\"target_points\"].keys()) == 1:\n",
    "\n",
    "    print(f\"All Factor: {CONVERT_ITERATION_All_TIME*1000:.3f} ms/iteration\")\n",
    "    print(f\"PE Factor: {CONVERT_ITERATION_PE_TIME*1000:.3f} ms/iteration\")\n",
    "    print(f\"SW Factor: {CONVERT_ITERATION_SW_TIME*1000:.3f} ms/iteration\")\n",
    "\n",
    "    # Color Map Setup\n",
    "    CMAP_NAME = 'jet'\n",
    "    n_targets = len(all_processed.keys())\n",
    "    discrete_cmap = plt.get_cmap(CMAP_NAME, n_targets + 1)\n",
    "    color_list_rgba = [discrete_cmap(i) for i in np.linspace(0, 1, n_targets + 1)]\n",
    "\n",
    "    for selectkey, colorIN in zip(all_processed.keys(),color_list_rgba):\n",
    "\n",
    "        # Get case type for time conversion\n",
    "        case = all_processed[selectkey][\"metadata\"][\"case\"]\n",
    "        if case == \"PE\": factor = CONVERT_ITERATION_PE_TIME\n",
    "        elif case == \"SW\": factor = CONVERT_ITERATION_SW_TIME\n",
    "        else: factor = CONVERT_ITERATION_All_TIME\n",
    "\n",
    "        targetIN =list(all_processed[selectkey][\"target_points\"].keys())[0]\n",
    "            \n",
    "        # Extract data\n",
    "        x_data = np.array(all_processed[selectkey][\"target_points\"][targetIN][\"iter\"]-1) * factor\n",
    "        y_data = abs(all_processed[selectkey][\"target_points\"][targetIN][\"E_vecs\"][:, 0])\n",
    "        y_err = all_processed[selectkey][\"target_points\"][targetIN][\"point_errors\"][:, 0]\n",
    "        target_point = all_processed[selectkey][\"target_points\"][targetIN][\"target_point\"]\n",
    "        \n",
    "        # Plot the data line\n",
    "        ax_main.plot(x_data, y_data, '-', color=colorIN, lw=1.5, \n",
    "                    label=f'{selectkey.split(\"_\")[0]} case: {selectkey.split(\"_\")[2]}')\n",
    "        \n",
    "        # Optional: Add error region\n",
    "        # ax_main.fill_between(x_data, y_data - y_err, y_data + y_err, \n",
    "        #                      color=colorIN, alpha=0.15, label=None)\n",
    "\n",
    "    ax_main.legend(loc=\"lower right\", fontsize=8, ncol=1)\n",
    "else: \n",
    "\n",
    "    selectkey = KEY_TARGET_MULTI\n",
    "    print(f\"Plotting multiple target points for key: {selectkey}\")\n",
    "\n",
    "    # Color Map Setup\n",
    "    CMAP_NAME = 'jet'\n",
    "    n_targets = len(all_processed[selectkey][\"target_points\"].keys())\n",
    "    discrete_cmap = plt.get_cmap(CMAP_NAME, n_targets + 1)\n",
    "    color_list_rgba = [discrete_cmap(i) for i in np.linspace(0, 1, n_targets + 1)]\n",
    "\n",
    "    # Get case type for time conversion\n",
    "    case = all_processed[selectkey][\"metadata\"][\"case\"]\n",
    "    if case == \"PE\": factor = CONVERT_ITERATION_PE_TIME\n",
    "    elif case == \"SW\": factor = CONVERT_ITERATION_SW_TIME\n",
    "    else: factor = CONVERT_ITERATION_All_TIME\n",
    "\n",
    "    print(f\"{case} Factor: {factor*1000:.3f} ms/iteration\")\n",
    "\n",
    "    # Plot each target point\n",
    "    for targetIN, colorIN in zip(all_processed[selectkey][\"target_points\"].keys(), color_list_rgba):\n",
    "        \n",
    "        # Extract data\n",
    "        x_data = np.array(all_processed[selectkey][\"target_points\"][targetIN][\"iter\"]-1) * factor\n",
    "        y_data = abs(all_processed[selectkey][\"target_points\"][targetIN][\"E_vecs\"][:, 0])\n",
    "        y_err = all_processed[selectkey][\"target_points\"][targetIN][\"point_errors\"][:, 0]\n",
    "        target_point = all_processed[selectkey][\"target_points\"][targetIN][\"target_point\"]\n",
    "        \n",
    "        # Plot the data line\n",
    "        ax_main.plot(x_data, y_data, '-', color=colorIN, lw=1.5, \n",
    "                    label=f'x:{target_point[0]:.3f} z:{target_point[2]:.3f}')\n",
    "        \n",
    "        # Optional: Add error region\n",
    "        # ax_main.fill_between(x_data, y_data - y_err, y_data + y_err, \n",
    "        #                      color=colorIN, alpha=0.15, label=None)\n",
    "\n",
    "    ax_main.legend(loc=\"upper left\", fontsize=8, ncol=2)\n",
    "\n",
    "# --- 6. FORMAT MAIN PLOT ---\n",
    "ax_main.set_xlabel(\"Time [s]\")\n",
    "ax_main.set_ylabel(r\"$|E_x|$ (V/m)\")\n",
    "# ax_main.ticklabel_format(axis='y', style='sci', scilimits=(0, 0))\n",
    "# ax_main.set_ylim(0, 2.2e5)\n",
    "ax_main.set_xlim(1e-1, 6)\n",
    "#ax_main.set_ylim(0,1e5)\n",
    "ax_main.grid(True, linestyle=':', alpha=0.5)\n",
    "\n",
    "# --- 7. SAVE AND SHOW ---\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"figures/field_evolution_target_points.jpeg\", bbox_inches=\"tight\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable LaTeX rendering\n",
    "mpl.rcParams['text.usetex'] = False\n",
    "# Set the global font size\n",
    "mpl.rcParams.update({'font.size': 12})\n",
    "\n",
    "# --- 1. CONFIGURATION AND DATA LOADING ---\n",
    "print(\"\\n--- Starting Data Processing and Plot Generation ---\")\n",
    "\n",
    "# Define Data Keys for Subtraction\n",
    "KEY_FIT = 'PE_425K_initial8max0.8final11_noDissipation_sphere40um_pos-0.1'\n",
    "KEY_TARGET = 'PE_425K_initial8max0.8final11_RefinedGridDissipation_sphere40um_pos-0.1'\n",
    "\n",
    "# NOTE: Since `all_processed` is not defined, the code below assumes it is a loaded dictionary\n",
    "# and will execute if the rest of your environment is set up.\n",
    "\n",
    "# Load external literature data\n",
    "zimmerman_SWdata = pd.read_csv(\"literature-data/Fig7a-SW.csv\")\n",
    "zimmerman_PEdata = pd.read_csv(\"literature-data/Fig7a-PE.csv\")\n",
    "zimmerman_PEandSWdata = pd.read_csv(\"literature-data/Fig7a-PE+SW.csv\")\n",
    "\n",
    "# Simulation Parameters (used for time conversion)\n",
    "WORLD_XY_AREA_SQ_M = 400 * 300 / (1e6**2)  # World area (m^2)\n",
    "PE_Ele_FLUX = 4e-6 * 6.241509e18\n",
    "SW_ION_FLUX = 3e-7 * 6.241509e18\n",
    "SW_Ele_FLUX = 1.5e-6 * 6.241509e18 # still dont know why the SW ele flux gives a difference conversion factor\n",
    "\n",
    "# PE Conversion Factor\n",
    "PARTICLES_PER_ITERATION_PE = 81775\n",
    "CONVERT_ITERATION_PE_TIME = PARTICLES_PER_ITERATION_PE / WORLD_XY_AREA_SQ_M / PE_Ele_FLUX\n",
    "\n",
    "# SW Conversion Factor\n",
    "PARTICLES_PER_ITERATION_SW = 14208\n",
    "CONVERT_ITERATION_SW_TIME = PARTICLES_PER_ITERATION_SW / WORLD_XY_AREA_SQ_M / SW_ION_FLUX\n",
    "\n",
    "# SW Conversion Factor\n",
    "PARTICLES_PER_ITERATION_All = 4452\n",
    "CONVERT_ITERATION_All_TIME = PARTICLES_PER_ITERATION_All / WORLD_XY_AREA_SQ_M / SW_ION_FLUX\n",
    "\n",
    "# Color Map Setup\n",
    "CMAP_NAME = 'Dark2'\n",
    "discrete_cmap = plt.get_cmap(CMAP_NAME, 8 + 1)\n",
    "color_list_rgba = [discrete_cmap(i) for i in np.linspace(0, 1, 8 + 1)]\n",
    "\n",
    "# --- Define specific color assignments ---\n",
    "# Request: SW (index 1), PE (index 2), All (index 4), Difference (index 2)\n",
    "CASE_COLOR_MAP = {\n",
    "    'SW': color_list_rgba[1],\n",
    "    'PE': color_list_rgba[2],\n",
    "    'All': color_list_rgba[4], # Assuming 'All' is the case type for combined PE+SW\n",
    "}\n",
    "# ---\n",
    "\n",
    "# --- 2. RAW SUBTRACTION AND DIFFERENCE CALCULATION ---\n",
    "\n",
    "print(\"\\n--- Performing Raw Subtraction (No Extrapolation) ---\")\n",
    "\n",
    "# 1. Extract Raw Data for KEY_FIT\n",
    "raw_fit_data = all_processed[KEY_FIT]['target_points']['target_0000']\n",
    "x_fit_raw = np.array(raw_fit_data[\"iter\"] - 1) * CONVERT_ITERATION_PE_TIME\n",
    "y_fit_raw = abs(raw_fit_data[\"E_vecs\"][:, 0])\n",
    "y_fit_errors_raw = raw_fit_data[\"point_errors\"][:, 0]\n",
    "\n",
    "# 2. Extract Raw Data for KEY_TARGET\n",
    "raw_target_data = all_processed[KEY_TARGET]['target_points']['target_0000']\n",
    "x_target_raw = np.array(raw_target_data[\"iter\"] - 1) * CONVERT_ITERATION_PE_TIME\n",
    "y_target_raw = abs(raw_target_data[\"E_vecs\"][:, 0])\n",
    "y_target_errors_raw = raw_target_data[\"point_errors\"][:, 0]\n",
    "\n",
    "# 3. Truncate to the length of the shortest array\n",
    "len_fit = len(x_fit_raw)\n",
    "len_target = len(x_target_raw)\n",
    "min_len = min(len_fit, len_target)\n",
    "\n",
    "print(f\"Truncating arrays to length: {min_len} (Fit len: {len_fit}, Target len: {len_target})\")\n",
    "\n",
    "# Truncated arrays\n",
    "x_common = x_fit_raw[:min_len]\n",
    "y_fit_trunc = y_fit_raw[:min_len]\n",
    "y_target_trunc = y_target_raw[:min_len]\n",
    "y_fit_errors_trunc = y_fit_errors_raw[:min_len]\n",
    "y_target_errors_trunc = y_target_errors_raw[:min_len]\n",
    "\n",
    "# Renaming for subsequent plotting code consistency (using the Fit data for the main plot line)\n",
    "x_plot = x_common\n",
    "y_plot_fit = y_fit_trunc # The data used as the basis (formerly y_extrapolated)\n",
    "y_plot_target = y_target_trunc # The data subtracted (formerly y_target)\n",
    "\n",
    "# 4. Raw Subtraction and Percent Difference Calculation\n",
    "y_raw_difference = abs(y_plot_fit - y_plot_target)\n",
    "method_label = f\"Raw Subtraction: |E_{KEY_FIT.split('_')[1]}| - |E_{KEY_TARGET.split('_')[1]}|\"\n",
    "\n",
    "# Define Percent Difference Denominator (KEY_FIT data)\n",
    "y_denominator = np.where(y_plot_fit == 0, 1e-10, y_plot_fit) \n",
    "y_percent_diff = (y_raw_difference / y_denominator) * 100 \n",
    "\n",
    "# --- Calculate Error Propagation for Difference and Percentage ---\n",
    "# Error propagation for the difference: sqrt(error_fit^2 + error_target^2)\n",
    "y_raw_difference_errors = np.sqrt(y_fit_errors_trunc**2 + y_target_errors_trunc**2)\n",
    "\n",
    "# Error propagation for the percentage\n",
    "# Using the simpler (more conservative) error formula for the difference term\n",
    "y_percent_diff_errors = (y_raw_difference_errors / np.abs(y_denominator)) * 100 \n",
    "\n",
    "# Renaming for plotting sections (3-6)\n",
    "x_extrapolate = x_plot\n",
    "y_extrapolated = y_plot_fit \n",
    "# ---------------------------------------------------\n",
    "\n",
    "# --- 3. PLOTTING SETUP (MAIN + SUBPLOT) ---\n",
    "\n",
    "# Set up figure and grid layout (5:1 height ratio for main plot vs. residual plot)\n",
    "fig = plt.figure(figsize=(7.01, 3.22))\n",
    "gs = gridspec.GridSpec(2, 1, hspace=0.1, height_ratios=[5, 1])\n",
    "\n",
    "# Main Plot (Top)\n",
    "ax_main = fig.add_subplot(gs[0])\n",
    "# Subtraction Plot (Bottom), sharing the x-axis\n",
    "ax_sub = fig.add_subplot(gs[1], sharex=ax_main)\n",
    "\n",
    "# --- 4. MAIN PLOT GENERATION (ax_main) ---\n",
    "\n",
    "# Plot reference data (Zimmerman)\n",
    "ax_main.plot(10**zimmerman_SWdata[\"x\"], zimmerman_SWdata[\" y\"], '-', color=\"k\", lw=3, alpha=0.3, label=None)\n",
    "ax_main.plot(10**zimmerman_PEdata[\"x\"], zimmerman_PEdata[\" y\"], '-', color=\"k\", lw=3, alpha=0.3)\n",
    "ax_main.plot(10**zimmerman_PEandSWdata[\"x\"], zimmerman_PEandSWdata[\" y\"], '--', color=\"k\", lw=3, alpha=0.3)\n",
    "\n",
    "# The old `color_list` is now replaced by the `CASE_COLOR_MAP` logic below.\n",
    "# Removed old line: color_list = [color_list_rgba[1],color_list_rgba[2],color_list_rgba[5],color_list_rgba[6]]\n",
    "# Removed old line: i=0\n",
    "\n",
    "# Plot the KEY_FIT data (Truncated) - Using the requested PE color (index 2)\n",
    "# NOTE: KEY_FIT is 'PE_425K...' so it should use the PE color.\n",
    "key_fit_case = KEY_FIT.split('_')[0] # 'PE'\n",
    "ax_main.plot(x_plot, y_plot_fit, '--', color=CASE_COLOR_MAP[key_fit_case], lw=1.5, \n",
    "             label=f\"Fit Case ({key_fit_case})\") # Changed to '--' to distinguish KEY_FIT/KEY_TARGET\n",
    "\n",
    "# Reset the counter for the main loop, if needed, but the logic should rely on `case`\n",
    "i = 0 \n",
    "for keyIN in all_processed.keys():\n",
    "    \n",
    "    # Define plotting variables outside of loop to use them later\n",
    "    case = all_processed[keyIN][\"metadata\"][\"case\"]\n",
    "    \n",
    "    if case == \"PE\": factor = CONVERT_ITERATION_PE_TIME\n",
    "    elif case == \"SW\": factor = CONVERT_ITERATION_SW_TIME\n",
    "    elif case == \"All\": factor = CONVERT_ITERATION_All_TIME\n",
    "    plot_color = CASE_COLOR_MAP[case]\n",
    "    \n",
    "    # Target and Temperature info (if needed for filtering/labeling, but not for color)\n",
    "    tempIN = all_processed[keyIN][\"metadata\"][\"temperature\"]\n",
    "    \n",
    "    x_data = np.array(all_processed[keyIN]['target_points']['target_0000'][\"iter\"] - 1) * factor\n",
    "    y_data = abs(all_processed[keyIN]['target_points']['target_0000'][\"E_vecs\"][:, 0])\n",
    "    y_err = all_processed[keyIN]['target_points']['target_0000'][\"point_errors\"][:, 0]\n",
    "    \n",
    "    print(keyIN)\n",
    "    \n",
    "    # Skip plotting the KEY_FIT line if it was already plotted above, or handle KEY_TARGET\n",
    "    # For now, plot all data using the new mapping.\n",
    "    \n",
    "    # Plot the data line\n",
    "    ax_main.plot(x_data, y_data, '-', color=plot_color, lw=1.5)\n",
    "    \n",
    "    # Use fill_between for the error region (Replaces errorbars)\n",
    "    ax_main.fill_between(x_data, y_data - y_err, y_data + y_err, \n",
    "                        color=plot_color, alpha=0.15, \n",
    "                        label=None) # Set label=None to avoid extra legend entry\n",
    "\n",
    "# Add original uncommented features back to ax_main\n",
    "#ax_main.axvline(x=65 * CONVERT_ITERATION_PE_TIME, color='gray', linestyle='-.', lw=1, alpha=0.7, label=\"Vertical Marker\")\n",
    "ax_main.set_ylabel(r\"$|E_x|$ (V/m)\")\n",
    "ax_main.ticklabel_format(axis='y', style='sci', scilimits=(0, 0))\n",
    "#ax_main.set_yscale('log') # Use log scale for better visualization of power-law decay\n",
    "ax_main.set_ylim(0,2.4e5) # Uncommented limits\n",
    "# ax_main.set_xlim(7.4e-1, 1.25e1) # Uncommented limits\n",
    "\n",
    "# Clean up main plot\n",
    "# ax_main.grid(True, linestyle=':', alpha=0.5)\n",
    "# ax_main.legend(loc='lower left', fontsize=8, ncol=2)\n",
    "# Remove X-tick labels from the main plot\n",
    "plt.setp(ax_main.get_xticklabels(), visible=False) \n",
    "ax_sub.set_ylabel(r\"% Diff\")\n",
    "\n",
    "# --- 5. SUBTRACTION PLOT GENERATION (ax_sub) ---\n",
    "\n",
    "# PLOT PERCENT DIFFERENCE WITH SHADED ERROR REGION\n",
    "# Color updated to index 2 (color_list_rgba[2])\n",
    "ax_sub.plot(x_extrapolate, y_percent_diff, '-', color=color_list_rgba[2], lw=2,\n",
    "            label=r\"Relative Error: $\\frac{|E_{Fit}| - |E_{Target}|}{|E_{Fit}|}$\")\n",
    "# Shaded region\n",
    "ax_sub.fill_between(x_extrapolate, y_percent_diff - y_percent_diff_errors, \n",
    "                    y_percent_diff + y_percent_diff_errors, \n",
    "                    color=color_list_rgba[2], alpha=0.2, label=\"Error Region\")\n",
    "ax_sub.set_xlabel(\"Lunar Equivalent Time [s]\")\n",
    "ax_sub.set_ylabel(r\"% Diff\")\n",
    "# ax_sub.ticklabel_format(axis='y', style='sci', scilimits=(0, 0)) # Removed, % difference is typically not sci notation\n",
    "# ax_sub.grid(True, linestyle=':', alpha=0.6)\n",
    "# ax_sub.legend(loc='upper right', fontsize=8)\n",
    "ax_sub.set_xlim(0,6) # Uncommented limit check (if sharing xlim works)\n",
    "ax_sub.set_ylim(0,10) # Uncommented limit check (if sharing xlim works)\n",
    "ax_sub.set_yticks([0,4,8])\n",
    "\n",
    "# --- 6. SAVE AND SHOW ---\n",
    "plt.savefig(\"figures/zimmerman_benchmark_summary.jpeg\", bbox_inches=\"tight\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_cmap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## 3D Representation of the Electric Pressure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration_SW, iteration_PE, iteration_All = 57, 131, 180\n",
    "print(f\"SW equivalent time for iteration#{iteration_SW}: {(iteration_SW-1)*CONVERT_ITERATION_SW_TIME}\")\n",
    "print(f\"PE equivalent time for iteration#{iteration_PE}: {(iteration_PE-1)*CONVERT_ITERATION_PE_TIME}\")\n",
    "print(f\"PE equivalent time for iteration#{iteration_All}: {(iteration_All-1)*CONVERT_ITERATION_All_TIME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "configIN = \"onlyphotoemission\"\n",
    "directory = \"raw-files/ZimmermanInitial8max0.8final11\"\n",
    "#directory = \"/storage/scratch1/5/avira7/Grain-Charging-Simulation-Data/build-dissipationRefinedGrid-initial8max0.8final12\"\n",
    "\n",
    "if iteration_PE <10 :\n",
    "    filenames = sorted(glob.glob(f\"{directory}/*00{iteration_PE}*{configIN}*.txt\")) #{iteration}\n",
    "else:\n",
    "    filenames = sorted(glob.glob(f\"{directory}/*{iteration_PE}*{configIN}*.txt\")) #{iteration}\n",
    "print(filenames)\n",
    "\n",
    "df_PE  = read_data_format_efficient(filenames,scaling=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "configIN = \"onlysolarwind\"\n",
    "directory = \"raw-files/ZimmermanInitial8max0.8final11\"\n",
    "#directory = \"/storage/scratch1/5/avira7/Grain-Charging-Simulation-Data/build-dissipationRefinedGrid-initial8max0.8final12\"\n",
    "\n",
    "if iteration_SW <10 :\n",
    "    filenames = sorted(glob.glob(f\"{directory}/*00{iteration_SW}*{configIN}*.txt\")) #{iteration}\n",
    "else:\n",
    "    filenames = sorted(glob.glob(f\"{directory}/*{iteration_SW}*{configIN}*.txt\")) #{iteration}\n",
    "print(filenames)\n",
    "\n",
    "df_SW = read_data_format_efficient(filenames,scaling=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_electrons = pd.read_pickle(\"processed-fieldmaps/PE_zimmerman_electrons_locations_until44.pkl\") #get it flipped when saving the files\n",
    "df_holes = pd.read_pickle(\"processed-fieldmaps/PE_zimmerman_protons_locations_until44.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_electrons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------\n",
    "# Step 0: Load field data and filter\n",
    "# -----------------------------------------\n",
    "fieldIN = df_PE[iteration_PE]\n",
    " \n",
    "geometry_center = geometry.centroid\n",
    "red_point = np.array([-0.1, 0., 0.1 + 0.037]) + geometry_center\n",
    " \n",
    "start_time = time.time()\n",
    "points = fieldIN[\"pos\"]\n",
    "vectors = fieldIN[\"E\"]\n",
    "magnitudes = fieldIN[\"E_mag\"]\n",
    " \n",
    "initial_mask = (magnitudes > 0) & (points[:,1]>=-0.1+geometry_center[1]) & (points[:,1]<=0.1+geometry_center[1])\n",
    "points = points[initial_mask]\n",
    "vectors = vectors[initial_mask]\n",
    "magnitudes = magnitudes[initial_mask]\n",
    " \n",
    "epsilon_0 = 8.854187817e-12\n",
    " \n",
    "# Create field cloud\n",
    "field_cloud = pv.PolyData(points)\n",
    "field_cloud[\"E_x\"] = vectors[:, 0]\n",
    "field_cloud[\"E_y\"] = vectors[:, 1]\n",
    "field_cloud[\"E_z\"] = vectors[:, 2]\n",
    " \n",
    "print(f\"Starting points (filtered): {len(points)}\")\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# Step 1: Create FULL geometry (before cropping)\n",
    "# ----------------------------------------------------\n",
    "start_time_geo = time.time()\n",
    " \n",
    "pv_spheres_full = pv.PolyData(\n",
    "    geometry.vertices,\n",
    "    np.hstack([np.full((len(geometry.faces), 1), 3), geometry.faces])\n",
    ").compute_normals()\n",
    "\n",
    "print(f\"Full geometry has {pv_spheres_full.n_cells} faces\")\n",
    "\n",
    "# ============================================================\n",
    "# Step 2: Calculate surface charge on FULL geometry\n",
    "# ============================================================\n",
    "num_faces_full = pv_spheres_full.n_cells\n",
    "face_charges_full = np.zeros(num_faces_full)\n",
    "\n",
    "# Face areas (m^2) for full geometry\n",
    "face_areas_m2_full = pv_spheres_full.compute_cell_sizes()['Area'] * 1e-6 + 1e-20\n",
    "\n",
    "q_proton = +1.602e-19\n",
    "q_electron = -1.602e-19\n",
    "\n",
    "# Get face centers for full geometry\n",
    "face_centers_full = pv_spheres_full.cell_centers().points\n",
    "\n",
    "# Build KDTree for fast nearest neighbor search\n",
    "tree = cKDTree(face_centers_full)\n",
    "\n",
    "# --- Particle positions ---\n",
    "e_pos = np.array(df_electrons[\"Post_Step_Position_mm\"].tolist())\n",
    "p_pos = np.array(df_protons[\"Post_Step_Position_mm\"].tolist())\n",
    "\n",
    "# --- Bin electrons to closest face ---\n",
    "if len(e_pos) > 0:\n",
    "    _, face_id_e = tree.query(e_pos, k=1)\n",
    "    unique_faces, counts = np.unique(face_id_e, return_counts=True)\n",
    "    face_charges_full[unique_faces] += counts * q_electron\n",
    "    print(f\"Binned {len(e_pos)} electrons to {len(unique_faces)} unique faces\")\n",
    "\n",
    "# --- Bin protons to closest face ---\n",
    "if len(p_pos) > 0:\n",
    "    _, face_id_p = tree.query(p_pos, k=1)\n",
    "    unique_faces, counts = np.unique(face_id_p, return_counts=True)\n",
    "    face_charges_full[unique_faces] += counts * q_proton\n",
    "    print(f\"Binned {len(p_pos)} protons to {len(unique_faces)} unique faces\")\n",
    "\n",
    "# --- Calculate surface charge density on full geometry ---\n",
    "sigma_per_face_SI_full = face_charges_full / face_areas_m2_full\n",
    "sigma_per_face_uC_full = sigma_per_face_SI_full * 1e6\n",
    "\n",
    "# Store charge data on full geometry\n",
    "pv_spheres_full.cell_data['charge_density_SI'] = sigma_per_face_SI_full\n",
    "pv_spheres_full.cell_data['charge_density_uC'] = sigma_per_face_uC_full\n",
    "\n",
    "# ============================================================\n",
    "# Step 3: Crop geometry to field bounds\n",
    "# ============================================================\n",
    "bbox_bounds = field_cloud.bounds\n",
    "bbox = pv.Box(bounds=bbox_bounds)\n",
    "\n",
    "pv_spheres_cropped = (\n",
    "    pv_spheres_full\n",
    "    .clip_box(bbox, invert=False)\n",
    "    .extract_surface()\n",
    "    .compute_normals(point_normals=True, cell_normals=True, inplace=False)\n",
    ")\n",
    "\n",
    "print(f\"Cropped geometry has {pv_spheres_cropped.n_cells} faces\")\n",
    "\n",
    "# ============================================================\n",
    "# Step 4: Interpolate E-field to cropped face centers\n",
    "# ============================================================\n",
    "face_centers_cropped = pv_spheres_cropped.cell_centers().points\n",
    " \n",
    "face_field_cloud = pv.PolyData(face_centers_cropped)\n",
    "face_field_interp = face_field_cloud.interpolate(\n",
    "    field_cloud,\n",
    "    radius=0.002,\n",
    "    strategy='closest_point',\n",
    "    sharpness=3.0,\n",
    "    null_value=0.0\n",
    ")\n",
    " \n",
    "# Extract face-centered E-fields\n",
    "E_x_faces = face_field_interp[\"E_x\"]\n",
    "E_y_faces = face_field_interp[\"E_y\"]\n",
    "E_z_faces = face_field_interp[\"E_z\"]\n",
    "E_vec_faces = np.stack([E_x_faces, E_y_faces, E_z_faces], axis=1)\n",
    " \n",
    "# Face normals (cropped geometry)\n",
    "face_normals = pv_spheres_cropped.cell_normals\n",
    "nx = face_normals[:, 0]   # x-direction component\n",
    " \n",
    "# ============================================================\n",
    "# Step 5: Compute Maxwell electric pressure (normal)\n",
    "# ============================================================\n",
    "E_dot_n = np.einsum('ij,ij->i', E_vec_faces, face_normals)\n",
    "E_mag_sq = np.einsum('ij,ij->i', E_vec_faces, E_vec_faces)\n",
    " \n",
    "# Normal pressure (scalar)\n",
    "P_normal_faces = epsilon_0 * (E_dot_n**2 - 0.5 * E_mag_sq)\n",
    " \n",
    "# ============================================================\n",
    "# Step 6: Compute X-directed electric pressure\n",
    "# ============================================================\n",
    "P_x_faces = P_normal_faces * nx\n",
    " \n",
    "# Save electric pressure to cropped mesh\n",
    "pv_spheres_cropped.cell_data[\"electric_pressure_x\"] = P_x_faces\n",
    "pv_spheres_cropped.cell_data[\"E_x\"] = E_x_faces\n",
    " \n",
    "print(f\"Computed x-directed electric pressure in {time.time() - start_time_geo:.2f}s\")\n",
    "\n",
    "# ============================================================\n",
    "# Step 7: Calculate F_x using charge density (Q * E_x)\n",
    "# ============================================================\n",
    "# Note: The cropped mesh inherited charge_density from the clipping operation\n",
    "# So we can use it directly\n",
    "sigma_cropped = pv_spheres_cropped.cell_data['charge_density_SI']\n",
    "\n",
    "# Calculate force: F = Q * E_x (not sigma * E_x * nx, that's wrong!)\n",
    "# The correct formula is F_x = Q_face * E_x\n",
    "pv_spheres_cropped.cell_data['F_x'] = sigma_cropped * E_x_faces #* nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "pv_spheres_cropped.cell_data['F_x'] = nx #sigma_cropped * E_x_faces #* nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Plotting using Px\n",
    "# ============================================================\n",
    "pl = pv.Plotter()\n",
    "pl.set_background('white')\n",
    " \n",
    "pl.add_mesh(\n",
    "    pv_spheres_cropped,\n",
    "    scalars=\"charge_density_SI\",\n",
    "    cmap=\"seismic\",\n",
    "    opacity=1,\n",
    "    show_edges=False,\n",
    "    clim=[-0.5e-5, 0.5e-5],\n",
    "    interpolate_before_map=False,\n",
    "    preference=\"cell\"\n",
    ")\n",
    " \n",
    "pl.view_xy()\n",
    "pl.show() #jupyter_backend='static'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ============================================================\n",
    "# Plotting using Px\n",
    "# ============================================================\n",
    "pl = pv.Plotter()\n",
    "pl.set_background('white')\n",
    " \n",
    "pl.add_mesh(\n",
    "    pv_spheres_cropped,\n",
    "    scalars=\"electric_pressure_x\",\n",
    "    cmap=\"seismic\",\n",
    "    opacity=1,\n",
    "    show_edges=False,\n",
    "    clim=[vmin, vmax],\n",
    "    interpolate_before_map=False,\n",
    "    preference=\"cell\"\n",
    ")\n",
    " \n",
    "pl.view_xy()\n",
    "pl.show(jupyter_backend='static')\n",
    " \n",
    "# ============================================================\n",
    "# Extract Line Plot Data (y=0 top surface)\n",
    "# ============================================================\n",
    "y_tolerance = 0.01\n",
    "z_min = 0.08\n",
    " \n",
    "x_centers = face_centers[:, 0]\n",
    "y_centers = face_centers[:, 1]\n",
    "z_centers = face_centers[:, 2]\n",
    " \n",
    "Px_faces = P_x_faces  # shorthand\n",
    " \n",
    "line_mask = (np.abs(y_centers) < y_tolerance) & (z_centers > z_min)\n",
    " \n",
    "x_line = x_centers[line_mask]\n",
    "z_line = z_centers[line_mask]\n",
    "Px_line = Px_faces[line_mask]\n",
    " \n",
    "# Bin + average\n",
    "x_bin_width = 0.005\n",
    "x_min, x_max = x_line.min(), x_line.max()\n",
    "x_bins = np.arange(x_min, x_max + x_bin_width, x_bin_width)\n",
    "x_bin_centers = (x_bins[:-1] + x_bins[1:]) / 2\n",
    " \n",
    "bin_indices = np.digitize(x_line, x_bins)\n",
    " \n",
    "x_line_avg, z_line_avg, Px_line_avg = [], [], []\n",
    " \n",
    "for i in range(1, len(x_bins)):\n",
    "    mask = (bin_indices == i)\n",
    "    if mask.any():\n",
    "        x_line_avg.append(x_line[mask].mean())\n",
    "        z_line_avg.append(z_line[mask].mean())\n",
    "        Px_line_avg.append(Px_line[mask].mean())\n",
    " \n",
    "# Sort\n",
    "x_line_sorted_PE = np.array(x_line_avg)\n",
    "z_line_sorted_PE = np.array(z_line_avg)\n",
    "pressure_line_sorted_PE = np.array(Px_line_avg)\n",
    " \n",
    "sort_idx = np.argsort(x_line_sorted_PE)\n",
    "x_line_sorted_PE = x_line_sorted_PE[sort_idx]\n",
    "z_line_sorted_PE = z_line_sorted_PE[sort_idx]\n",
    "pressure_line_sorted_PE = pressure_line_sorted_PE[sort_idx]\n",
    " \n",
    "print(f\"Extracted {len(x_line)} raw points, averaged into {len(x_line_sorted_PE)} bins along y=0 line\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------\n",
    "# Your existing setup code here...\n",
    "# -----------------------------------------\n",
    "fieldIN = df_SW[iteration_SW]\n",
    "vmin, vmax = (-0.05, 0.05) \n",
    " \n",
    "geometry_center = geometry.centroid\n",
    "red_point = np.array([-0.1, 0., 0.1 + 0.037]) + geometry_center\n",
    " \n",
    "# ----------------------------------------------------\n",
    "# Step 0: Filter data\n",
    "# ----------------------------------------------------\n",
    "start_time = time.time()\n",
    "points = fieldIN[\"pos\"]\n",
    "vectors = fieldIN[\"E\"]\n",
    "magnitudes = fieldIN[\"E_mag\"]\n",
    " \n",
    "initial_mask = (magnitudes > 0) & (points[:,1]>=-0.1+geometry_center[1]) & (points[:,1]<=0.1+geometry_center[1])\n",
    "points = points[initial_mask]\n",
    "vectors = vectors[initial_mask]\n",
    "magnitudes = magnitudes[initial_mask]\n",
    " \n",
    "epsilon_0 = 8.854187817e-12\n",
    " \n",
    "# Create field cloud\n",
    "field_cloud = pv.PolyData(points)\n",
    "field_cloud[\"E_x\"] = vectors[:, 0]\n",
    "field_cloud[\"E_y\"] = vectors[:, 1]\n",
    "field_cloud[\"E_z\"] = vectors[:, 2]\n",
    " \n",
    "print(f\"Starting points (filtered): {len(points)}\")\n",
    " \n",
    "# ----------------------------------------------------\n",
    "# Step 1: Geometry Setup\n",
    "# ----------------------------------------------------\n",
    "start_time_geo = time.time()\n",
    " \n",
    "pv_spheres = pv.PolyData(\n",
    "    geometry.vertices,\n",
    "    np.hstack([np.full((len(geometry.faces), 1), 3), geometry.faces])\n",
    ").compute_normals()\n",
    " \n",
    "bbox_bounds = field_cloud.bounds\n",
    "bbox = pv.Box(bounds=bbox_bounds)\n",
    "pv_spheres_cropped = (\n",
    "    pv_spheres\n",
    "    .clip_box(bbox, invert=False)\n",
    "    .extract_surface()\n",
    "    .compute_normals(point_normals=True, cell_normals=True, inplace=False)\n",
    ")\n",
    " \n",
    "# ============================================================\n",
    "# Interpolate field to face centers\n",
    "# ============================================================\n",
    "face_centers = pv_spheres_cropped.cell_centers().points\n",
    " \n",
    "face_field_cloud = pv.PolyData(face_centers)\n",
    "face_field_interp = face_field_cloud.interpolate(\n",
    "    field_cloud,\n",
    "    radius=0.002,\n",
    "    strategy='closest_point',\n",
    "    sharpness=3.0,\n",
    "    null_value=0.0\n",
    ")\n",
    " \n",
    "# Extract face-centered E-fields\n",
    "E_x_faces = face_field_interp[\"E_x\"]\n",
    "E_y_faces = face_field_interp[\"E_y\"]\n",
    "E_z_faces = face_field_interp[\"E_z\"]\n",
    "\n",
    "E_vec_faces = np.stack([E_x_faces, E_y_faces, E_z_faces], axis=1)\n",
    "#E_vec_mag_faces = np.sqrt(E_x_faces**2 + E_y_faces **2 + E_z_faces **2)\n",
    "# Face normals\n",
    "face_normals = pv_spheres_cropped.cell_normals\n",
    "nx = face_normals[:, 0]   # <-- x-direction component\n",
    "\n",
    "# ============================================================\n",
    "# Compute Maxwell electric pressure (normal)\n",
    "# ============================================================\n",
    "E_dot_n = np.einsum('ij,ij->i', E_vec_faces, face_normals)\n",
    "E_mag_sq = np.einsum('ij,ij->i', E_vec_faces, E_vec_faces)\n",
    " \n",
    "# Normal pressure (scalar)\n",
    "P_normal_faces = epsilon_0 * (E_dot_n**2 - 0.5 * E_mag_sq)\n",
    "#P_normal_faces = epsilon_0 * (E_vec_mag_faces**2 ) /2 #- 0.5 * E_mag_sq)\n",
    " \n",
    "# ============================================================\n",
    "# Compute X-directed electric pressure\n",
    "# ============================================================\n",
    "P_x_faces = P_normal_faces * nx   # <-- THIS IS WHAT YOU WANTED\n",
    " \n",
    "# Save to cell data\n",
    "pv_spheres_cropped.cell_data[\"electric_pressure_x\"] = P_x_faces\n",
    " \n",
    "print(f\"Computed x-directed electric pressure in {time.time() - start_time_geo:.2f}s\")\n",
    " \n",
    "# ============================================================\n",
    "# Plotting using Px\n",
    "# ============================================================\n",
    "pl = pv.Plotter()\n",
    "pl.set_background('white')\n",
    " \n",
    "pl.add_mesh(\n",
    "    pv_spheres_cropped,\n",
    "    scalars=\"electric_pressure_x\",\n",
    "    cmap=\"seismic\",\n",
    "    opacity=1,\n",
    "    show_edges=False,\n",
    "    clim=[vmin, vmax],\n",
    "    interpolate_before_map=False,\n",
    "    preference=\"cell\"\n",
    ")\n",
    " \n",
    "pl.view_xy()\n",
    "pl.show() #jupyter_backend='static'\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "E_vec_faces.magitude??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable LaTeX rendering\n",
    "mpl.rcParams['text.usetex'] = False\n",
    "# Set the global font size\n",
    "mpl.rcParams.update({'font.size': 14})\n",
    "\n",
    "cmap = plt.cm.seismic \n",
    "#vmin, vmax = (-1, 1)\n",
    "norm = mpl.colors.Normalize(vmin=vmin, vmax=vmax)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 0.1))\n",
    "\n",
    "# --- 1. Create and Configure the ScalarFormatter ---\n",
    "formatter = ticker.ScalarFormatter(useMathText=True)\n",
    "\n",
    "formatter.set_useOffset(False) \n",
    "formatter.set_powerlimits((0, 0)) \n",
    "\n",
    "# --- 2. Create the Colorbar and apply the Formatter ---\n",
    "cb = mpl.colorbar.ColorbarBase(\n",
    "    ax, \n",
    "    cmap=cmap, \n",
    "    norm=norm, \n",
    "    orientation='horizontal', label=r\"Electric Pressure, x (Pa)\"\n",
    ")\n",
    "\n",
    "# Apply the formatter to the colorbar's x-axis\n",
    "cb.ax.xaxis.set_major_formatter(formatter)\n",
    "\n",
    "# --- 3. Display the Plot ---\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable LaTeX rendering\n",
    "mpl.rcParams['text.usetex'] = False\n",
    "# Set the global font size\n",
    "mpl.rcParams.update({'font.size': 14})\n",
    "\n",
    "cmap = plt.cm.seismic \n",
    "vmin, vmax = (-1,1) \n",
    "norm = mpl.colors.Normalize(vmin=vmin, vmax=vmax)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 0.1))\n",
    "\n",
    "# --- 1. Create and Configure the ScalarFormatter ---\n",
    "formatter = ticker.ScalarFormatter(useMathText=True)\n",
    "\n",
    "formatter.set_useOffset(False) \n",
    "formatter.set_powerlimits((0, 0)) \n",
    "\n",
    "# --- 2. Create the Colorbar and apply the Formatter ---\n",
    "cb = mpl.colorbar.ColorbarBase(\n",
    "    ax, \n",
    "    cmap=cmap, \n",
    "    norm=norm, \n",
    "    orientation='horizontal', label=r\"Electric Pressure, x (Pa)\"\n",
    ")\n",
    "\n",
    "# Apply the formatter to the colorbar's x-axis\n",
    "cb.ax.xaxis.set_major_formatter(formatter)\n",
    "\n",
    "# --- 3. Display the Plot ---\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_protons = pd.read_pickle(\"processed-fieldmaps/SW_zimmerman_electrons_locations_until44.pkl\") #get it flipped when saving the files\n",
    "df_electrons = pd.read_pickle(\"processed-fieldmaps/SW_zimmerman_protons_locations_until44.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_charge_density(electrons, protons, convex_combined, vmin=0, vmax=1e-3):\n",
    " \n",
    "    # --- 1. Initialize Charge and Area Arrays ---\n",
    "    num_faces = len(convex_combined.faces)\n",
    "    face_charges = np.zeros(num_faces)\n",
    "    face_areas_m2 = convex_combined.area_faces * 1e-6\n",
    "    # Add a small epsilon to prevent division by zero for any zero-area faces\n",
    "    face_areas_m2 += 1e-20\n",
    "\n",
    "    q_proton = +1.602e-19\n",
    "    q_electron = -1.602e-19\n",
    " \n",
    "    # --- 2. Get Particle Positions ---\n",
    "    # We get positions in mm, as the trimesh object is in mm\n",
    "    e_pos = np.array(electrons[\"Post_Step_Position_mm\"].tolist())\n",
    "    p_pos = np.array(protons[\"Post_Step_Position_mm\"].tolist())\n",
    " \n",
    "    # --- 3. Bin Electrons and Protons to Faces to get Q_face ---\n",
    "    # Bin electrons\n",
    "    if len(e_pos) > 0:\n",
    "        # Find the closest face ID for each electron\n",
    "        _, _, face_id_e = convex_combined.nearest.on_surface(e_pos)\n",
    "        # Find unique faces and how many electrons hit each one\n",
    "        unique_faces_e, counts_e = np.unique(face_id_e, return_counts=True)\n",
    "        # Add the total charge from these electrons to the face_charges array\n",
    "        # Q_face = N_electrons * q_electron\n",
    "        face_charges[unique_faces_e] += (counts_e * q_electron)\n",
    " \n",
    "    # Bin protons\n",
    "    if len(p_pos) > 0:\n",
    "        # Find the closest face ID for each proton\n",
    "        _, _, face_id_p = convex_combined.nearest.on_surface(p_pos)\n",
    "        # Find unique faces and how many protons hit each one\n",
    "        unique_faces_p, counts_p = np.unique(face_id_p, return_counts=True)\n",
    "        # Add the total charge from these protons to the face_charges array\n",
    "        # Q_face = N_protons * q_proton\n",
    "        face_charges[unique_faces_p] += (counts_p * q_proton)\n",
    " \n",
    "    # --- 4. Calculate Surface Charge Density (sigma) ---\n",
    "    # sigma = Q_face / A_face (in uC/m^2)\n",
    "    sigma_per_face = face_charges*1e6 / face_areas_m2\n",
    "    # # --- 5. Calculate Electric Pressure (P) ---\n",
    "    # # P = sigma^2 / (2 * epsilon_0) (in Pascals, N/m^2)\n",
    "    # face_pressures = (sigma_per_face**2) / (2.0 * epsilon_0)\n",
    " \n",
    "    # --- 6. Apply Colormap ---\n",
    "    colors_rgba = np.zeros((num_faces, 4), dtype=np.uint8)\n",
    "    # Pressure is always positive (it's squared), so use a sequential colormap\n",
    "    # like 'hot', 'viridis', or 'plasma' instead of 'seismic'.\n",
    "    cmap = plt.cm.BrBG #plt.cm.hot\n",
    "    norm_func = Normalize(vmin=vmin, vmax=vmax)\n",
    "    colors_rgb = cmap(norm_func(sigma_per_face))[:, :3]\n",
    " \n",
    "    # Assign RGB to all faces\n",
    "    colors_rgba[:, :3] = (colors_rgb * 255).astype(np.uint8)\n",
    "    # Set alpha to opaque so faces are visible\n",
    "    colors_rgba[:, 3] = 255\n",
    " \n",
    "    # Apply colors to mesh\n",
    "    convex_combined.visual.face_colors = colors_rgba\n",
    " \n",
    "    return convex_combined, sigma_per_face, colors_rgba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "surf, interation0,_ = plot_charge_density(df_electrons, df_protons, geometry, vmin=-5, vmax=5)\n",
    "# Make sure each triangle has its own unique vertices\n",
    "surface_edited = surf.copy()\n",
    "surface_edited.unmerge_vertices()\n",
    "surface_edited.visual.vertex_colors = None\n",
    "surface_edited.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------------------\n",
    "# Your existing setup code here...\n",
    "# -----------------------------------------\n",
    "fieldIN = df_SW[iteration_SW]\n",
    "vmin, vmax = (-0.05, 0.05) \n",
    " \n",
    "geometry_center = geometry.centroid\n",
    " \n",
    "# ----------------------------------------------------\n",
    "# Step 0: Filter data\n",
    "# ----------------------------------------------------\n",
    "start_time = time.time()\n",
    "points = fieldIN[\"pos\"]\n",
    "vectors = fieldIN[\"E\"]\n",
    "magnitudes = fieldIN[\"E_mag\"]\n",
    " \n",
    "initial_mask = (magnitudes > 0) & (points[:,1]>=-0.1+geometry_center[1]) & (points[:,1]<=0.1+geometry_center[1])\n",
    "points = points[initial_mask]\n",
    "vectors = vectors[initial_mask]\n",
    "magnitudes = magnitudes[initial_mask]\n",
    " \n",
    "epsilon_0 = 8.854187817e-12\n",
    " \n",
    "# Create field cloud\n",
    "field_cloud = pv.PolyData(points)\n",
    "field_cloud[\"E_x\"] = vectors[:, 0]\n",
    "field_cloud[\"E_y\"] = vectors[:, 1]\n",
    "field_cloud[\"E_z\"] = vectors[:, 2]\n",
    " \n",
    "print(f\"Starting points (filtered): {len(points)}\")\n",
    "\n",
    "pv_spheres = pv.PolyData(\n",
    "    geometry.vertices,\n",
    "    np.hstack([np.full((len(geometry.faces), 1), 3), geometry.faces])\n",
    ").compute_normals()\n",
    " \n",
    "bbox_bounds = field_cloud.bounds\n",
    "bbox = pv.Box(bounds=bbox_bounds)\n",
    "pv_spheres_cropped = (\n",
    "    pv_spheres\n",
    "    .clip_box(bbox, invert=False)\n",
    "    .extract_surface()\n",
    "    .compute_normals(point_normals=True, cell_normals=True, inplace=False)\n",
    ")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Interpolate field to face centers\n",
    "# ============================================================\n",
    "face_centers = pv_spheres_cropped.cell_centers().points\n",
    " \n",
    "face_field_cloud = pv.PolyData(face_centers)\n",
    "face_field_interp = face_field_cloud.interpolate(\n",
    "    field_cloud,\n",
    "    radius=0.002,\n",
    "    strategy='closest_point',\n",
    "    sharpness=3.0,\n",
    "    null_value=0.0\n",
    ")\n",
    " \n",
    "# Extract face-centered E-fields\n",
    "E_x_faces = face_field_interp[\"E_x\"]\n",
    "E_y_faces = face_field_interp[\"E_y\"]\n",
    "E_z_faces = face_field_interp[\"E_z\"]\n",
    "\n",
    "# --- 1. Compute face areas ---\n",
    "face_areas_m2 = pv_spheres_cropped.compute_cell_sizes()['Area'] * 1e-6  # mm^2 -> m^2\n",
    "face_areas_m2 += 1e-20  # prevent division by zero\n",
    "# --- 2. Initialize face charges ---\n",
    "num_faces = pv_spheres_cropped.n_cells\n",
    "face_charges = np.zeros(num_faces)\n",
    "q_proton = +1.602e-19\n",
    "q_electron = -1.602e-19\n",
    "# --- 3. Bin electrons to faces ---\n",
    "e_pos = np.array(df_electrons[\"Post_Step_Position_mm\"].tolist())\n",
    "if len(e_pos) > 0:\n",
    "    face_id_e = pv_spheres_cropped.find_closest_cell(e_pos)\n",
    "    valid_mask = face_id_e >= 0\n",
    "    face_id_e = face_id_e[valid_mask]\n",
    "    unique_faces, counts = np.unique(face_id_e, return_counts=True)\n",
    "    face_charges[unique_faces] += counts * q_electron\n",
    "# --- 4. Bin protons to faces ---\n",
    "p_pos = np.array(df_protons[\"Post_Step_Position_mm\"].tolist())\n",
    "if len(p_pos) > 0:\n",
    "    face_id_p = pv_spheres_cropped.find_closest_cell(p_pos)\n",
    "    valid_mask = face_id_p >= 0\n",
    "    face_id_p = face_id_p[valid_mask]\n",
    "    unique_faces, counts = np.unique(face_id_p, return_counts=True)\n",
    "    face_charges[unique_faces] += counts * q_proton\n",
    "# --- 5. Surface charge density (C/m^2) ---\n",
    "sigma_per_face = face_charges / face_areas_m2\n",
    "pv_spheres_cropped.cell_data['charge_density'] = sigma_per_face\n",
    "# --- 6. Extract X-component of face-centered E-field ---\n",
    "# E_x_faces = face_field_interp[\"E_x\"]\n",
    "# --- 7. Compute X-directed force per face (F = Q * E_x) ---\n",
    "# Q_face = sigma * A_face -> F_x = Q_face * E_x = sigma * A * E_x\n",
    "F_x_faces = sigma_per_face * E_x_faces\n",
    "pv_spheres_cropped.cell_data['F_x'] = F_x_faces\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "interation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Plotting using Px\n",
    "# ============================================================\n",
    "pl = pv.Plotter()\n",
    "pl.set_background('white')\n",
    " \n",
    "pl.add_mesh(\n",
    "    pv_spheres_cropped,\n",
    "    scalars=\"charge_density\",\n",
    "    cmap=\"seismic\",\n",
    "    opacity=1,\n",
    "    show_edges=False,\n",
    "    #clim=[-0.5, 0.5],\n",
    "    interpolate_before_map=False,\n",
    "    preference=\"cell\"\n",
    ")\n",
    " \n",
    "pl.view_xy()\n",
    "pl.show() #jupyter_backend='static'\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyvista-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
